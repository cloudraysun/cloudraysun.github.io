<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>初学爬虫（6）——信息提取和标记，第一次鸽了</title>
    <link href="/2020/08/17/%E5%88%9D%E5%AD%A6%E7%88%AC%E8%99%AB%EF%BC%886%EF%BC%89%E2%80%94%E2%80%94%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96%E5%92%8C%E6%A0%87%E8%AE%B0%EF%BC%8C%E7%AC%AC%E4%B8%80%E6%AC%A1%E9%B8%BD%E4%BA%86/"/>
    <url>/2020/08/17/%E5%88%9D%E5%AD%A6%E7%88%AC%E8%99%AB%EF%BC%886%EF%BC%89%E2%80%94%E2%80%94%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96%E5%92%8C%E6%A0%87%E8%AE%B0%EF%BC%8C%E7%AC%AC%E4%B8%80%E6%AC%A1%E9%B8%BD%E4%BA%86/</url>
    
    <content type="html"><![CDATA[<p>&emsp;今天，不，应该说是昨天，第一次彻底鸽了。我现在的状态是一天写，一天休息，虽然每天会花大量时间在驾校上，但不代表没有时间去做这些。本来12点前是能够写完的，但临时有事，回来后发现也赶不完了，最后还是这样写完了。这算是Flag破功的第一次吧，希望不会有下一次了。<br><img src="https://img-blog.csdnimg.cn/20200817003521704.jpg#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><hr><h1 id="信息标记"><a href="#信息标记" class="headerlink" title="信息标记"></a>信息标记</h1><p>信息的标记使信息能够更有效地表达，有助于理解信息的真实含义。<br>也可以理解为标明信息是哪一方面的，如地点，名字，时间等。</p><h2 id="信息标记作用"><a href="#信息标记作用" class="headerlink" title="信息标记作用"></a>信息标记作用</h2><p>1：标记后的信息可形成信息组织结构，增加了信息维度。<br>2：标记的结构与信息一样具有重要价值。<br>3：标记后的信息可用于通信、存储或展示。<br>4：标记后的信息更利于程序（人）理解和运用。<br>以HTML的信息标记为例：<br>HTML：Huper text  markup language，超文本标记语言，<br>是WWW(World Wide Web)的信息组织方式，<br>可以将图像、声音、视频等超文本信息嵌入到文本之中。<br>HTML通过预定义的&lt;&gt;…&lt;/&gt;标签形式组织不同类型的信息。</p><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">html</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">head</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">title</span>&gt;</span>This is a python demo page<span class="hljs-tag">&lt;/<span class="hljs-name">title</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">head</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">body</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">p</span> <span class="hljs-attr">class</span>=<span class="hljs-string">"title"</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">b</span>&gt;</span>The demo python introduces several python courses.<span class="hljs-tag">&lt;/<span class="hljs-name">b</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">p</span> <span class="hljs-attr">class</span>=<span class="hljs-string">"course"</span>&gt;</span>Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:<span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">href</span>=<span class="hljs-string">"http://www.icourse163.org/course/BIT-268001"</span> <span class="hljs-attr">class</span>=<span class="hljs-string">"py1"</span> <span class="hljs-attr">id</span>=<span class="hljs-string">"link1"</span>&gt;</span>Basic Python<span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span> and<span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">href</span>=<span class="hljs-string">"http://www.icourse163.org/course/BIT-1001870001"</span> <span class="hljs-attr">class</span>=<span class="hljs-string">"py2"</span> <span class="hljs-attr">id</span>=<span class="hljs-string">"link2"</span>&gt;</span>Advanced Python<span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span>.<span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span></code></pre><h2 id="信息标记种类"><a href="#信息标记种类" class="headerlink" title="信息标记种类"></a>信息标记种类</h2><p>目前国际上公认的较为广泛的信息标记种类有三种：<br>XML，JSON，YAMLL</p><h3 id="XML"><a href="#XML" class="headerlink" title="XML"></a>XML</h3><p>eXtensible Markup Language<br>XML出现时间比HTML晚，可以认为是HTML的通用表达版本。</p><p><img src="https://img-blog.csdnimg.cn/20200817002013764.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">img</span> <span class="hljs-attr">src</span>=<span class="hljs-string">“china.jpg”</span> <span class="hljs-attr">size</span>=<span class="hljs-string">“10”</span>&gt;</span> … <span class="hljs-tag">&lt;/<span class="hljs-name">img</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">img</span> <span class="hljs-attr">src</span>=<span class="hljs-string">“china.jpg”</span> <span class="hljs-attr">size</span>=<span class="hljs-string">“10”</span> /&gt;</span>如果标签没有内容，即...中没有内容，空元素的缩写形式<span class="hljs-tag">&lt;<span class="hljs-name">!‐‐</span> <span class="hljs-attr">This</span> <span class="hljs-attr">is</span> <span class="hljs-attr">a</span> <span class="hljs-attr">comment</span>, <span class="hljs-attr">very</span> <span class="hljs-attr">useful</span> ‐‐&gt;</span>注释书写形式</code></pre><p>基础格式：</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span> … <span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> 如果有内容<span class="hljs-tag">&lt;<span class="hljs-name">name</span> /&gt;</span> 简写，没有内容<span class="hljs-tag">&lt;<span class="hljs-name">!‐‐注释</span> ‐‐&gt;</span></code></pre><p>实例：</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">person</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">firstName</span>&gt;</span>Tian<span class="hljs-tag">&lt;/<span class="hljs-name">firstName</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">lastName</span>&gt;</span>Song<span class="hljs-tag">&lt;/<span class="hljs-name">lastName</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">address</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">streetAddr</span>&gt;</span>中关村南大街5号<span class="hljs-tag">&lt;/<span class="hljs-name">streetAddr</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">city</span>&gt;</span>北京市<span class="hljs-tag">&lt;/<span class="hljs-name">city</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">zipcode</span>&gt;</span>100081<span class="hljs-tag">&lt;/<span class="hljs-name">zipcode</span>&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">address</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">prof</span>&gt;</span>Computer System<span class="hljs-tag">&lt;/<span class="hljs-name">prof</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">prof</span>&gt;</span>Security<span class="hljs-tag">&lt;/<span class="hljs-name">prof</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">person</span>&gt;</span></code></pre><h3 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h3><p>JavsScript Object Notation<br>javaScricpt语言中面向对象表达的一种表达形式。<br>通过键值对表达。<br>对于一部分语言，此格式可以直接作为程序的一部分，便于简化程序。<br><img src="https://img-blog.csdnimg.cn/20200817002030387.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><pre><code class="hljs json">"name":"中国""name":["中国","北京"] 多值"name":&#123;    "newname":"北京"    "oldname":"燕京"&#125; 键值对嵌套</code></pre><p>基础格式：</p><pre><code class="hljs json">"key": "value""key": ["value1", "value2"]"key": &#123;    "subkey": "subvalue"&#125;</code></pre><p>实例：</p><pre><code class="hljs json">&#123;    “firstName” : “Tian” ,    “lastName” : “Song” ,    “address” : &#123;        “streetAddr” : “中关村南大街5号” ,        “city” : “北京市” ,        “zipcode” : “100081”        &#125; ,    “prof” : [ “Computer System” , “Security” ]&#125;</code></pre><h3 id="YAML"><a href="#YAML" class="headerlink" title="YAML"></a>YAML</h3><p>YAML Ain’t Markup Language<br>最为简洁的表达形式，采用无类型键值对表达。<br>无双引号””结构，key值仅限字符串</p><pre><code class="hljs yaml"><span class="hljs-string">name:中国</span><span class="hljs-comment">#表达注释</span><span class="hljs-string">name:#名字</span><span class="hljs-string">通过缩进表达关系</span><span class="hljs-attr">name :</span>    <span class="hljs-attr">newName :</span> <span class="hljs-string">北京</span>    <span class="hljs-attr">oldName :</span> <span class="hljs-string">燕京</span><span class="hljs-string">表达并列关系</span><span class="hljs-attr">name:</span><span class="hljs-string">-北京</span><span class="hljs-string">-燕京</span><span class="hljs-string">|表达整块内容，#表示注释</span><span class="hljs-attr">text:</span> <span class="hljs-string">|</span> <span class="hljs-comment">#注释</span><span class="hljs-string">北京市，简称“京”，古称燕京、北平，是中华人民共和国首都、省级行政区、直辖市、国家中心城市、超大城市，国务院批复确定的中国政治中心、文化中心、国际交往中心、科技创新中心</span> <span class="hljs-string">[1]</span>  <span class="hljs-string">。</span></code></pre><p>基础格式：</p><pre><code class="hljs yaml"><span class="hljs-attr">key :</span> <span class="hljs-string">value</span><span class="hljs-attr">key :</span> <span class="hljs-comment">#Comment</span><span class="hljs-string">‐value1</span><span class="hljs-string">‐value2</span><span class="hljs-attr">key :</span>    <span class="hljs-attr">subkey :</span> <span class="hljs-string">subvalue</span></code></pre><p>实例：</p><pre><code class="hljs yaml"><span class="hljs-attr">firstName :</span> <span class="hljs-string">Tian</span><span class="hljs-attr">lastName :</span> <span class="hljs-string">Song</span><span class="hljs-attr">address :</span>    <span class="hljs-attr">streetAddr :</span> <span class="hljs-string">中关村南大街5号</span>    <span class="hljs-attr">city :</span> <span class="hljs-string">北京市</span>    <span class="hljs-attr">zipcode :</span> <span class="hljs-number">100081</span><span class="hljs-attr">prof :</span><span class="hljs-string">‐Computer</span> <span class="hljs-string">System</span><span class="hljs-string">‐Security</span></code></pre><h2 id="信息标记形式比较"><a href="#信息标记形式比较" class="headerlink" title="信息标记形式比较"></a>信息标记形式比较</h2><table><thead><tr><th>形式</th><th>比较</th><th>应用</th></tr></thead><tbody><tr><td>XML</td><td>最早的通用信息标记语言，可扩展性好，但繁琐。</td><td>Internet上的信息交互与传递</td></tr><tr><td>JSON</td><td>信息有类型，适合程序处理(js)，较XML简洁。</td><td>移动应用云端和节点的信息通信，无注释</td></tr><tr><td>YAML</td><td>信息无类型，文本（有效）信息比例最高，</td><td>可读性好。  各类系统的配置文件，有注释易读</td></tr></tbody></table><h1 id="信息提取"><a href="#信息提取" class="headerlink" title="信息提取"></a>信息提取</h1><p>从标记后的信息中提取所关注的内容。<br>XML JSON YAML</p><table><thead><tr><th>方法</th><th>需求</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>完整解析信息的标记形式，再提取关键信息</td><td>需要标记解析器，例如：bs4库的标签树遍历</td><td>信息解析准确</td><td>提取过程繁琐，速度慢</td></tr><tr><td>无视标记形式，直接搜索关键信息</td><td>搜索，对信息的文本查找函数即可</td><td>提取过程简洁，速度较快</td><td>提取结果准确性与信息内容相关</td></tr><tr><td>融合方法,结合形式解析与搜索方法，提取关键信息</td><td>需要标记解析器及文本查找函数</td><td></td><td></td></tr></tbody></table><p>实例：<br>需求：提取HTML中所有URL连接<br>思路：<br>1：搜索到所有<code>&lt;a&gt;</code>标签<br>2：解析<code>&lt;a&gt;</code>标签内容，提取href后的连接内容</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> requests<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.get(<span class="hljs-string">"http://python123.io/ws/demo.html"</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>demo = r.text<span class="hljs-meta">&gt;&gt;&gt; </span>demo<span class="hljs-string">'&lt;html&gt;&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;\r\n&lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\r\n&lt;a href="http://www.icourse163.org/course/BIT-268001" class="py1" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a href="http://www.icourse163.org/course/BIT-1001870001" class="py2" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;\r\n&lt;/body&gt;&lt;/html&gt;'</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="hljs-string">"html.parser"</span>) <span class="hljs-comment">#将demo做成汤</span><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> link <span class="hljs-keyword">in</span> soup.find_all(<span class="hljs-string">'a'</span>):print(link.get(<span class="hljs-string">'href'</span>))http://www.icourse163.org/course/BIT<span class="hljs-number">-268001</span>http://www.icourse163.org/course/BIT<span class="hljs-number">-1001870001</span></code></pre><h1 id="基于bs4库的HTML内容查找方法"><a href="#基于bs4库的HTML内容查找方法" class="headerlink" title="基于bs4库的HTML内容查找方法"></a>基于bs4库的HTML内容查找方法</h1><h2 id="lt-gt-find-all"><a href="#lt-gt-find-all" class="headerlink" title="&lt;&gt;.find_all"></a>&lt;&gt;.find_all</h2><p>&lt;&gt;.find_all(name, attrs, recursive, string, **kwargs)<br>返回一个列表类型，存储查找的结果<br>name : 对标签名称的检索字符串<br>attrs: 对标签属性值的检索字符串，可标注属性检索<br>recursive: 是否对子孙全部检索，默认True<br>string: &lt;&gt;…&lt;/&gt;中字符串区域的检索字符串</p><p>注：以下示例均基于此demo：</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> requests<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.get(<span class="hljs-string">"http://python123.io/ws/demo.html"</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>demo = r.text<span class="hljs-meta">&gt;&gt;&gt; </span>demo<span class="hljs-string">'&lt;html&gt;&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;\r\n&lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\r\n&lt;a href="http://www.icourse163.org/course/BIT-268001" class="py1" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a href="http://www.icourse163.org/course/BIT-1001870001" class="py2" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;\r\n&lt;/body&gt;&lt;/html&gt;'</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="hljs-string">"html.parser"</span>) <span class="hljs-comment">#将demo做成汤</span></code></pre><p>name : 对标签名称的检索字符串</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>soup.find_all(<span class="hljs-string">"a"</span>)[&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt;, &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;]<span class="hljs-meta">&gt;&gt;&gt; </span>soup.find_all([<span class="hljs-string">'a'</span>,<span class="hljs-string">'b'</span>])[&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;, &lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt;, &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;]<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> tag <span class="hljs-keyword">in</span> soup.find_all(<span class="hljs-literal">True</span>): <span class="hljs-comment">#显示所有标签信息</span>print(tag.name)htmlheadtitlebodypbpaa<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> re <span class="hljs-comment">#正则模块</span><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> tag <span class="hljs-keyword">in</span> soup.find_all(re.compile(<span class="hljs-string">'b'</span>)):print(tag.name)bodyb</code></pre><p>attrs: 对标签属性值的检索字符串，可标注属性检索</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>soup.find_all(<span class="hljs-string">'p'</span>,<span class="hljs-string">'course'</span>)<span class="hljs-comment">#可以检索某个标签的属性中是否具有相关信息</span>[&lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;]<span class="hljs-meta">&gt;&gt;&gt; </span>soup.find_all(id=<span class="hljs-string">'link'</span>) <span class="hljs-comment">#精确查找属性域中id为link的标签</span>[]<span class="hljs-meta">&gt;&gt;&gt; </span>soup.find_all(id=<span class="hljs-string">'link1'</span>)[&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt;]<span class="hljs-meta">&gt;&gt;&gt; </span>soup.find_all(id=re.compile(<span class="hljs-string">'link'</span>))[&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt;, &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;]</code></pre><p>recursive: 是否对子孙全部检索，默认True，默认搜索soup下的所有节点。为False时，只搜索soup下的直接子节点</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>soup.find_all(<span class="hljs-string">'a'</span>)[&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt;, &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;]<span class="hljs-meta">&gt;&gt;&gt; </span>soup.find_all(<span class="hljs-string">'a'</span>,recursive=<span class="hljs-literal">False</span>) [] <span class="hljs-comment">#说明soup的子节点没有'a'标签</span></code></pre><p>string:精确查找 &lt;&gt;…&lt;/&gt;中字符串区域的检索字符串</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>soup&lt;html&gt;&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;&lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;<span class="hljs-meta">&gt;&gt;&gt; </span>soup.find_all(string=<span class="hljs-string">"Basic Python"</span>)[<span class="hljs-string">'Basic Python'</span>]<span class="hljs-meta">&gt;&gt;&gt; </span>soup.find_all(string=re.compile(<span class="hljs-string">'python'</span>))[<span class="hljs-string">'This is a python demo page'</span>, <span class="hljs-string">'The demo python introduces several python courses.'</span>]</code></pre><h2 id="简写形式"><a href="#简写形式" class="headerlink" title="简写形式"></a>简写形式</h2><p>由于.find_all是bs4的最常用方法，可以使用其简写形式：</p><pre><code class="hljs python">&lt;tag&gt;(..) 等价于&lt;tag&gt;.find_all(..)soup(..) 等价于soup.find_all(..)</code></pre><p>即</p><pre><code class="hljs python">soup.find_all(<span class="hljs-string">"a"</span>) = soup(<span class="hljs-string">"a"</span>)soup.title.find_all(text=<span class="hljs-literal">True</span>) = soup.title(text=<span class="hljs-literal">True</span>)</code></pre><h2 id="扩展方法"><a href="#扩展方法" class="headerlink" title="扩展方法"></a>扩展方法</h2><table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>&lt;&gt;.find()</td><td>搜索且只返回一个结果，同.find_all()参数</td></tr><tr><td>&lt;&gt;.find_parents()</td><td>在先辈节点中搜索，返回列表类型，同.find_all()参数</td></tr><tr><td>&lt;&gt;.find_parent()</td><td>在先辈节点中返回一个结果，同.find()参数</td></tr><tr><td>&lt;&gt;.find_next_siblings()</td><td>在后续平行节点中搜索，返回列表类型，同.find_all()参数</td></tr><tr><td>&lt;&gt;.find_next_sibling()</td><td>在后续平行节点中返回一个结果，同.find()参数</td></tr><tr><td>&lt;&gt;.find_previous_siblings()</td><td>在前序平行节点中搜索，返回列表类型，同.find_all()参数</td></tr><tr><td>&lt;&gt;.find_previous_sibling()</td><td>在前序平行节点中返回一个结果，同.find()参数</td></tr></tbody></table><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><img src="https://img-blog.csdnimg.cn/20200817002234639.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br><strong>课程来源：<a href="https://www.icourse163.org/learn/BIT-1001870001?tid=1450316449#/learn/announce" target="_blank" rel="noopener">北京理工大学MOOC</a></strong></p>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>学习记录</tag>
      
      <tag>爬虫</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>初学爬虫（5）——Beautiful Soup库基础</title>
    <link href="/2020/08/14/%E5%88%9D%E5%AD%A6%E7%88%AC%E8%99%AB%EF%BC%885%EF%BC%89%E2%80%94%E2%80%94Beautiful%20Soup%E5%BA%93%E5%9F%BA%E7%A1%80/"/>
    <url>/2020/08/14/%E5%88%9D%E5%AD%A6%E7%88%AC%E8%99%AB%EF%BC%885%EF%BC%89%E2%80%94%E2%80%94Beautiful%20Soup%E5%BA%93%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<p>&emsp;今天正式公布开学时间了，放了大半年的假期，终于快结束了。然而回去就要期末考试，看着还未动过的课本，还没开始复习（预习）啊！！！<br><img src="https://img-blog.csdnimg.cn/20200814224145545.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><hr><p>&emsp;Beautiful Soup库用于<strong>解析HTML页面，可用于标记和提取信息</strong>。<br>&emsp;在其官网<a href="https://www.crummy.com/software/BeautifulSoup/上的介绍如下：" target="_blank" rel="noopener">https://www.crummy.com/software/BeautifulSoup/上的介绍如下：</a></p><p><img src="https://img-blog.csdnimg.cn/20200814220149144.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><p>翻译为：<br><img src="https://img-blog.csdnimg.cn/20200814220157399.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><h1 id="Beautiful-Soup库的引用"><a href="#Beautiful-Soup库的引用" class="headerlink" title="Beautiful Soup库的引用"></a>Beautiful Soup库的引用</h1><p>Beautiful Soup库，也叫Beautiful Soup4或bs4<br>一般引用方式为</p><pre><code class="hljs python"><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup <span class="hljs-comment">#从bs4中，引入BeautifulSoup这个类</span></code></pre><p>也可以直接引用</p><pre><code class="hljs python"><span class="hljs-keyword">import</span> bs4</code></pre><h1 id="Beautiful-Soup库基础理解"><a href="#Beautiful-Soup库基础理解" class="headerlink" title="Beautiful Soup库基础理解"></a>Beautiful Soup库基础理解</h1><p>以HTML库页面为例。<br>Beautiful Soup库是解析、遍历、维护”标签树“的功能库，可以解析以标签树为基本格式的文档。<br><img src="https://img-blog.csdnimg.cn/20200814220353681.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><p>可以认为HTML文档&lt;=&gt;标签树&lt;=&gt;BeautifulSoup类，互相等价，BeautifulSoup对应一个HTML/XML文档的全部内容。<br>在此基础上，可以使标签树成为一个变量，对其BeautifulSoup类的改变，可等价于改变标签树<br><img src="https://img-blog.csdnimg.cn/20200814220406538.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><h1 id="Beautiful-Soup库解析器"><a href="#Beautiful-Soup库解析器" class="headerlink" title="Beautiful Soup库解析器"></a>Beautiful Soup库解析器</h1><p>都可以有效解析HTML/XMl文档，使用不同解析器会产生些微差距，需根据实际情况选择。<br>可供参考<br><a href="https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/#id53" target="_blank" rel="noopener">https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/#id53</a></p><pre><code class="hljs python">soup = BeautifulSoup(<span class="hljs-string">'&lt;html&gt;data&lt;/html&gt;'</span>，<span class="hljs-string">'解析器种类'</span>)</code></pre><table><thead><tr><th>解析器</th><th>使用方法</th><th>优势</th><th>劣势</th></tr></thead><tbody><tr><td>Python标准库</td><td>BeautifulSoup(markup, “html.parser”)</td><td>Python的内置标准库，执行速度适中</td><td>Python 2.7.3 or (3.2.2)前 的版本中文档容错能力差</td></tr><tr><td>lxml HTML 解析器</td><td>BeautifulSoup(markup, “lxml”)</td><td>速度快 ，文档容错能力强</td><td>需要安装C语言库</td></tr><tr><td>lxml XML解析器</td><td>BeautifulSoup(markup, [“lxml”, “xml”])、BeautifulSoup(markup, “xml”)</td><td>速度快 ，唯一支持XML的解析器</td><td>需要安装C语言库</td></tr><tr><td>html5lib</td><td>BeautifulSoup(markup, “html5lib”)</td><td>最好的容错性，以浏览器的方式解析文档，生成HTML5格式的文档</td><td>速度慢，不依赖外部扩展</td></tr><tr><td>作者：马小跳_</td><td></td><td></td><td></td></tr><tr><td>链接：<a href="https://www.jianshu.com/p/5e23d2c90500" target="_blank" rel="noopener">https://www.jianshu.com/p/5e23d2c90500</a></td><td></td><td></td><td></td></tr><tr><td>来源：简书</td><td></td><td></td><td></td></tr></tbody></table><h1 id="BeautifulSoup类的基本元素"><a href="#BeautifulSoup类的基本元素" class="headerlink" title="BeautifulSoup类的基本元素"></a>BeautifulSoup类的基本元素</h1><p><code>&lt;p&gt;...&lt;/p&gt;</code>为标签<br>p为名称，<br>class=”title”为属性，用于定义标签特点，<br>class属性内容为”title”，属性可以说由键值对构成，class为键，title为值。</p><p><img src="https://img-blog.csdnimg.cn/20200814220706447.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><h2 id="基本元素说明"><a href="#基本元素说明" class="headerlink" title="基本元素说明"></a>基本元素说明</h2><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">p</span> <span class="hljs-attr">class</span>=<span class="hljs-string">“title”</span>&gt;</span> … <span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span>'</code></pre><p>Tag 标签，最基本的信息组织单元，分别用&lt;&gt;和&lt;/&gt;标明开头和结尾<br>Name 标签的名字，<code>&quot;&lt;p&gt;…&lt;/p&gt;&quot;</code>的名字是’p’，格式：<tag>.name<br>Attributes 标签的属性，字典形式组织，格式：<tag>.attrs<br>NavigableString 标签内非属性字符串，&lt;&gt;…&lt;/&gt;中字符串，格式：<tag>.string<br>Comment 标签内字符串的注释部分，一种特殊的Comment类型</p><h2 id="demo页面示例："><a href="#demo页面示例：" class="headerlink" title="demo页面示例："></a>demo页面示例：</h2><p>以下示例均基于<a href="http://python123.io/ws/demo.html网站" target="_blank" rel="noopener">http://python123.io/ws/demo.html网站</a></p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> requests<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.get(<span class="hljs-string">"http://python123.io/ws/demo.html"</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>demo = r.text<span class="hljs-meta">&gt;&gt;&gt; </span>demo<span class="hljs-string">'&lt;html&gt;&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;\r\n&lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\r\n&lt;a href="http://www.icourse163.org/course/BIT-268001" class="py1" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a href="http://www.icourse163.org/course/BIT-1001870001" class="py2" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;\r\n&lt;/body&gt;&lt;/html&gt;'</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="hljs-string">"html.parser"</span>) <span class="hljs-comment">#将demo做成汤</span></code></pre><p>Tag 标签</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>soup.title <span class="hljs-comment">#soup标签</span>&lt;title&gt;This is a python demo page&lt;/title&gt;<span class="hljs-meta">&gt;&gt;&gt; </span>tag = soup.a <span class="hljs-comment">#获得第一个a标签内容，任何标签都可以通过soup.tag方式获得，存在多个时，返回第一个</span><span class="hljs-meta">&gt;&gt;&gt; </span>tag&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt;</code></pre><p>Name 标签名字</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>soup.a.name <span class="hljs-comment">#soup标签名字</span><span class="hljs-string">'a'</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup.a.parent.name <span class="hljs-comment">#获得其父类名字</span><span class="hljs-string">'p'</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup.a.parent.parent.name<span class="hljs-string">'body'</span></code></pre><p>Attributes 标签的属性</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>tag = soup.a<span class="hljs-meta">&gt;&gt;&gt; </span>tag.attrs <span class="hljs-comment">#获取标签属性，若没有则返回空字典</span>&#123;<span class="hljs-string">'href'</span>: <span class="hljs-string">'http://www.icourse163.org/course/BIT-268001'</span>, <span class="hljs-string">'class'</span>: [<span class="hljs-string">'py1'</span>], <span class="hljs-string">'id'</span>: <span class="hljs-string">'link1'</span>&#125;<span class="hljs-meta">&gt;&gt;&gt; </span>tag.attrs[<span class="hljs-string">'class'</span>] <span class="hljs-comment">#获取属性内容列表</span>[<span class="hljs-string">'py1'</span>]<span class="hljs-meta">&gt;&gt;&gt; </span>tag.attrs[<span class="hljs-string">'href'</span>]<span class="hljs-string">'http://www.icourse163.org/course/BIT-268001'</span><span class="hljs-meta">&gt;&gt;&gt; </span>type(tag.attrs[<span class="hljs-string">'class'</span>]) <span class="hljs-comment">#标签属性类型</span>&lt;<span class="hljs-class"><span class="hljs-keyword">class</span> '<span class="hljs-title">list</span>'&gt;</span><span class="hljs-class">&gt;&gt;&gt; <span class="hljs-title">type</span><span class="hljs-params">(tag.attrs)</span></span><span class="hljs-class">&lt;<span class="hljs-title">class</span> '<span class="hljs-title">dict</span>'&gt;</span><span class="hljs-class">&gt;&gt;&gt; <span class="hljs-title">type</span><span class="hljs-params">(tag)</span>#标签类型，特殊定义</span><span class="hljs-class">&lt;<span class="hljs-title">class</span> '<span class="hljs-title">bs4</span>.<span class="hljs-title">element</span>.<span class="hljs-title">Tag</span>'&gt;</span></code></pre><p>NavigableString 标签内非属性字符串</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>tag = soup.a <span class="hljs-meta">&gt;&gt;&gt; </span>soup.a.string <span class="hljs-comment">#标签内非属性字符串</span><span class="hljs-string">'Basic Python'</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup.p&lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;<span class="hljs-meta">&gt;&gt;&gt; </span>soup.p.string <span class="hljs-comment">#标签内非属性字符串，可跨越多层次</span><span class="hljs-string">'The demo python introduces several python courses.'</span><span class="hljs-meta">&gt;&gt;&gt; </span>type(soup.p.string)&lt;<span class="hljs-class"><span class="hljs-keyword">class</span> '<span class="hljs-title">bs4</span>.<span class="hljs-title">element</span>.<span class="hljs-title">NavigableString</span>'&gt;</span></code></pre><p>Comment 标签内字符串的注释部分</p><pre><code class="hljs python"><span class="hljs-comment">#当获取非属性字符串时，注释和非注释需要通过其类型分辨</span><span class="hljs-meta">&gt;&gt;&gt; </span>newsoup =  BeautifulSoup(<span class="hljs-string">"&lt;b&gt;&lt;!--Comment--&gt;&lt;/b&gt;&lt;p&gt;not comment&lt;/p&gt;"</span>,<span class="hljs-string">"html.parser"</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>newsoup.b.string<span class="hljs-string">'Comment'</span><span class="hljs-meta">&gt;&gt;&gt; </span>type(newsoup.b.string)&lt;<span class="hljs-class"><span class="hljs-keyword">class</span> '<span class="hljs-title">bs4</span>.<span class="hljs-title">element</span>.<span class="hljs-title">Comment</span>'&gt;  #注释类型</span><span class="hljs-class">&gt;&gt;&gt; <span class="hljs-title">newsoup</span>.<span class="hljs-title">p</span>.<span class="hljs-title">string</span></span><span class="hljs-class">'<span class="hljs-title">not</span> <span class="hljs-title">comment</span>'</span><span class="hljs-class">&gt;&gt;&gt; <span class="hljs-title">type</span><span class="hljs-params">(newsoup.p.string)</span></span><span class="hljs-class">&lt;<span class="hljs-title">class</span> '<span class="hljs-title">bs4</span>.<span class="hljs-title">element</span>.<span class="hljs-title">NavigableString</span>'&gt; #非属性字符串类型</span></code></pre><p><img src="https://img-blog.csdnimg.cn/20200814221506568.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><h1 id="基于bs4库的HTML内容遍历方法"><a href="#基于bs4库的HTML内容遍历方法" class="headerlink" title="基于bs4库的HTML内容遍历方法"></a>基于bs4库的HTML内容遍历方法</h1><h2 id="HTML基本格式"><a href="#HTML基本格式" class="headerlink" title="HTML基本格式"></a>HTML基本格式</h2><p><img src="https://img-blog.csdnimg.cn/20200814221518166.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>例子<br>树形结构的文本信息<br><img src="https://img-blog.csdnimg.cn/2020081422155274.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><h2 id="HTML遍历方式"><a href="#HTML遍历方式" class="headerlink" title="HTML遍历方式"></a>HTML遍历方式</h2><p><img src="https://img-blog.csdnimg.cn/20200814221602129.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><p>BeautifulSoup类型是标签树的根节点</p><h3 id="下行遍历"><a href="#下行遍历" class="headerlink" title="下行遍历"></a>下行遍历</h3><table><thead><tr><th>属性</th><th>说明</th></tr></thead><tbody><tr><td>.contents</td><td>将<tag>所有儿子节点存入列表，返回列表类型</td></tr><tr><td>.children</td><td>与.contents类似，用于循环遍历儿子节点</td></tr><tr><td>.descendants</td><td>包含所有子孙节点，用于循环遍历</td></tr><tr><td>注：.contents返回为列表类型，剩下两个返回为迭代类型</td><td></td></tr></tbody></table><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> requests<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.get(<span class="hljs-string">"http://python123.io/ws/demo.html"</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>demo = r.text<span class="hljs-meta">&gt;&gt;&gt; </span>demo<span class="hljs-string">'&lt;html&gt;&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;\r\n&lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\r\n&lt;a href="http://www.icourse163.org/course/BIT-268001" class="py1" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a href="http://www.icourse163.org/course/BIT-1001870001" class="py2" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;\r\n&lt;/body&gt;&lt;/html&gt;'</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="hljs-string">"html.parser"</span>) <span class="hljs-comment">#将demo做成汤</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup.head&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;<span class="hljs-meta">&gt;&gt;&gt; </span>soup.head.contents <span class="hljs-comment">#head的儿子节点</span>[&lt;title&gt;This is a python demo page&lt;/title&gt;]<span class="hljs-meta">&gt;&gt;&gt; </span>soup.head.children&lt;list_iterator object at <span class="hljs-number">0x000001CB341392E8</span>&gt;<span class="hljs-comment">#对于一个标签的儿子节点，不仅包括标签字典，也包括字符串节点，例如'\n'</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup.body.contents['\n', &lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;, '\n', &lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;, '\n']<span class="hljs-meta">&gt;&gt;&gt; </span>len(soup.body.contents)<span class="hljs-number">5</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup.body.contents[<span class="hljs-number">1</span>]&lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;</code></pre><p>遍历基本结构</p><pre><code class="hljs python"><span class="hljs-keyword">for</span> child <span class="hljs-keyword">in</span> soup.body.children: <span class="hljs-comment">#遍历儿子节点</span>    print(child)<span class="hljs-keyword">for</span> child <span class="hljs-keyword">in</span> soup.body.descendants: <span class="hljs-comment">#遍历子孙节点</span>    print(child)</code></pre><h3 id="上行遍历"><a href="#上行遍历" class="headerlink" title="上行遍历"></a>上行遍历</h3><p>.parent 节点的父亲标签<br>.parents 节点先辈标签的迭代类型，用于循环遍历先辈节点</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> requests<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.get(<span class="hljs-string">"http://python123.io/ws/demo.html"</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>demo = r.text<span class="hljs-meta">&gt;&gt;&gt; </span>demo<span class="hljs-string">'&lt;html&gt;&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;\r\n&lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\r\n&lt;a href="http://www.icourse163.org/course/BIT-268001" class="py1" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a href="http://www.icourse163.org/course/BIT-1001870001" class="py2" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;\r\n&lt;/body&gt;&lt;/html&gt;'</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="hljs-string">"html.parser"</span>) <span class="hljs-comment">#将demo做成汤</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup.title.parent&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;<span class="hljs-meta">&gt;&gt;&gt; </span>soup.html.parent<span class="hljs-comment">#html为最高级标签，故其父标签即为自己</span>&lt;html&gt;&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;&lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;<span class="hljs-meta">&gt;&gt;&gt; </span>soup.parent<span class="hljs-meta">&gt;&gt;&gt; </span>print(soup.parent)<span class="hljs-literal">None</span></code></pre><p>遍历结构<br>遍历所有先辈节点，包括soup本身，所以要区别判断</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> parent <span class="hljs-keyword">in</span> soup.a.parents: <span class="hljs-comment">#遍历a的所有先辈节点</span><span class="hljs-keyword">if</span> parent <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>: <span class="hljs-comment">#soup父节点为None</span>print(parent)<span class="hljs-keyword">else</span>:print(parent.name)pbodyhtml[document]</code></pre><h3 id="平行遍历"><a href="#平行遍历" class="headerlink" title="平行遍历"></a>平行遍历</h3><table><thead><tr><th>属性</th><th>说明</th></tr></thead><tbody><tr><td>.next_sibling</td><td>返回按照HTML文本顺序的下一个平行节点标签</td></tr><tr><td>.previous_sibling</td><td>返回按照HTML文本顺序的上一个平行节点标签</td></tr><tr><td>.next_siblings</td><td>迭代类型，返回按照HTML文本顺序的后续所有平行节点标签</td></tr><tr><td>.previous_siblings</td><td>迭代类型，返回按照HTML文本顺序的前续所有平行节点标签</td></tr></tbody></table><p><strong>必须要在同一个父节点下的节点，才能进行平行遍历</strong><br><img src="https://img-blog.csdnimg.cn/20200814221917272.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> requests<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.get(<span class="hljs-string">"http://python123.io/ws/demo.html"</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>demo = r.text<span class="hljs-meta">&gt;&gt;&gt; </span>demo<span class="hljs-string">'&lt;html&gt;&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;\r\n&lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\r\n&lt;a href="http://www.icourse163.org/course/BIT-268001" class="py1" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a href="http://www.icourse163.org/course/BIT-1001870001" class="py2" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;\r\n&lt;/body&gt;&lt;/html&gt;'</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="hljs-string">"html.parser"</span>) <span class="hljs-comment">#将demo做成汤</span><span class="hljs-comment">#在标签之间的NavigableString，即标签内非属性字符串，也构成了节点</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup.a.next_sibling <span class="hljs-comment">#任意节点的平行节点使存在NavigableString的</span><span class="hljs-string">' and '</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup.a.next_sibling<span class="hljs-string">' and '</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup.a.next_sibling.next_sibling&lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;Advanced Python&lt;/a&gt;<span class="hljs-meta">&gt;&gt;&gt; </span>soup.a.previous_sibling<span class="hljs-string">'Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\r\n'</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup.a.previous_sibling.previous_sibling&gt;&gt;&gt;</code></pre><p>基础结构</p><pre><code class="hljs python"><span class="hljs-keyword">for</span> sibling <span class="hljs-keyword">in</span> soup.a.next_sibling: <span class="hljs-comment">#遍历后续节点</span>    print(sibling)<span class="hljs-keyword">for</span> sibling <span class="hljs-keyword">in</span> soup.a.previous_sibling: <span class="hljs-comment">#遍历前续节点</span>    print(sibling)</code></pre><p><img src="https://img-blog.csdnimg.cn/20200814222100593.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><h1 id="基于bs4库的HTML格式输出"><a href="#基于bs4库的HTML格式输出" class="headerlink" title="基于bs4库的HTML格式输出"></a>基于bs4库的HTML格式输出</h1><p>使HTML文档格式显示更友好<br>.prettify()：<br>.prettify()为HTML文本&lt;&gt;及其内容增加更加’\n’，使其打印时自动换行<br>.prettify()可用于标签，方法：<tag>.prettify()</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> requests<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.get(<span class="hljs-string">"http://python123.io/ws/demo.html"</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>demo = r.text<span class="hljs-meta">&gt;&gt;&gt; </span>demo<span class="hljs-string">'&lt;html&gt;&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;p class="title"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;\r\n&lt;p class="course"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\r\n&lt;a href="http://www.icourse163.org/course/BIT-268001" class="py1" id="link1"&gt;Basic Python&lt;/a&gt; and &lt;a href="http://www.icourse163.org/course/BIT-1001870001" class="py2" id="link2"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;\r\n&lt;/body&gt;&lt;/html&gt;'</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(demo,<span class="hljs-string">"html.parser"</span>) <span class="hljs-comment">#将demo做成汤</span><span class="hljs-meta">&gt;&gt;&gt; </span>soup.prettify()<span class="hljs-string">'&lt;html&gt;\n &lt;head&gt;\n  &lt;title&gt;\n   This is a python demo page\n  &lt;/title&gt;\n &lt;/head&gt;\n &lt;body&gt;\n  &lt;p class="title"&gt;\n   &lt;b&gt;\n    The demo python introduces several python courses.\n   &lt;/b&gt;\n  &lt;/p&gt;\n  &lt;p class="course"&gt;\n   Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\n   &lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;\n    Basic Python\n   &lt;/a&gt;\n   and\n   &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;\n    Advanced Python\n   &lt;/a&gt;\n   .\n  &lt;/p&gt;\n &lt;/body&gt;\n&lt;/html&gt;'</span><span class="hljs-meta">&gt;&gt;&gt; </span>print(soup.prettify())&lt;html&gt; &lt;head&gt;  &lt;title&gt;   This <span class="hljs-keyword">is</span> a python demo page  &lt;/title&gt; &lt;/head&gt; &lt;body&gt;  &lt;p class="title"&gt;   &lt;b&gt;    The demo python introduces several python courses.   &lt;/b&gt;  &lt;/p&gt;  &lt;p class="course"&gt;   Python <span class="hljs-keyword">is</span> a wonderful general-purpose programming language. You can learn Python <span class="hljs-keyword">from</span> novice to professional by tracking the following courses:   &lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt;    Basic Python   &lt;/a&gt;   <span class="hljs-keyword">and</span>   &lt;a class="py2" href="http://www.icourse163.org/course/BIT-1001870001" id="link2"&gt;    Advanced Python   &lt;/a&gt;   .  &lt;/p&gt; &lt;/body&gt;&lt;/html&gt;<span class="hljs-meta">&gt;&gt;&gt; </span>print(soup.a.prettify())&lt;a class="py1" href="http://www.icourse163.org/course/BIT-268001" id="link1"&gt; Basic Python&lt;/a&gt;&gt;&gt;&gt;</code></pre><h1 id="bs4库的编码"><a href="#bs4库的编码" class="headerlink" title="bs4库的编码"></a>bs4库的编码</h1><p>bs4库将任何HTML输入都变成utf‐8编码<br>Python 3.x默认支持编码是utf‐8,解析无障碍</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>soup = BeautifulSoup(<span class="hljs-string">"&lt;P&gt;中文&lt;/p&gt;"</span>,<span class="hljs-string">"html.parser"</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>soup.p.string<span class="hljs-string">'中文'</span><span class="hljs-meta">&gt;&gt;&gt; </span>print(soup.p.prettify())&lt;p&gt; 中文&lt;/p&gt;</code></pre><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><img src="https://img-blog.csdnimg.cn/20200814222131823.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><h1 id="课程内容来源"><a href="#课程内容来源" class="headerlink" title="课程内容来源"></a>课程内容来源</h1><p>中国大学MOOC—北京理工大学—嵩天教授—Python网络爬虫与信息提取<br><a href="https://www.icourse163.org/course/BIT-1001870001?tid=1450316449" target="_blank" rel="noopener">https://www.icourse163.org/course/BIT-1001870001?tid=1450316449</a></p>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>学习记录</tag>
      
      <tag>爬虫</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>初学爬虫（4）——Requests库实例操作，第一次打脸</title>
    <link href="/2020/08/12/%E5%88%9D%E5%AD%A6%E7%88%AC%E8%99%AB%EF%BC%884%EF%BC%89%E2%80%94%E2%80%94Requests%E5%BA%93%E5%AE%9E%E4%BE%8B%E6%93%8D%E4%BD%9C%EF%BC%8C%E7%AC%AC%E4%B8%80%E6%AC%A1%E6%89%93%E8%84%B8/"/>
    <url>/2020/08/12/%E5%88%9D%E5%AD%A6%E7%88%AC%E8%99%AB%EF%BC%884%EF%BC%89%E2%80%94%E2%80%94Requests%E5%BA%93%E5%AE%9E%E4%BE%8B%E6%93%8D%E4%BD%9C%EF%BC%8C%E7%AC%AC%E4%B8%80%E6%AC%A1%E6%89%93%E8%84%B8/</url>
    
    <content type="html"><![CDATA[<p>&emsp;这篇内容很少，本来应该昨天就应该写完，最后在12点前补完。</p><hr><p>&emsp;以下爬虫实例，均直接通过网页连接查询。此处关键在于明白通过API的灵活使用来获取资源。因还未学习BeautifulSoup库，故此处实例爬取页面均为原始页面。</p><h1 id="京东商品页面爬取"><a href="#京东商品页面爬取" class="headerlink" title="京东商品页面爬取"></a>京东商品页面爬取</h1><p>&emsp;以下为全部代码</p><pre><code class="hljs python"><span class="hljs-keyword">import</span> requestsheader = &#123;<span class="hljs-string">"User-Agent"</span>: <span class="hljs-string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36"</span><span class="hljs-comment">#Mozilla/5.0标准浏览器标识（可带表多种浏览器）</span>            &#125;url = <span class="hljs-string">"https://item.jd.com/100001484839.html"</span><span class="hljs-keyword">try</span>:    r = requests.get(url,headers = header)    r.raise_for_status() <span class="hljs-comment">#如果不是200，则产生异常requests.HTTPErrir</span>    r.encoding =r.apparent_encoding <span class="hljs-comment">#根据页面内容，采取编码</span>    print(r.text[:<span class="hljs-number">1000</span>])<span class="hljs-keyword">except</span>:    print(<span class="hljs-string">"连接异常"</span>)</code></pre><pre><code class="hljs python">&lt;!DOCTYPE HTML&gt;&lt;html lang=<span class="hljs-string">"zh-CN"</span>&gt;&lt;head&gt;    &lt;!-- shouji --&gt;    &lt;meta http-equiv=<span class="hljs-string">"Content-Type"</span> content=<span class="hljs-string">"text/html; charset=utf-8"</span> /&gt;    &lt;title&gt;【索尼【PS4 Pro 国行主机】PlayStation 4 Pro 电脑娱乐游戏主机 1TB（黑色）2018版】索尼（SONY）PS4 Pro PlayStation国行游戏机 1TB主机（黑色）【行情 报价 价格 评测】-京东&lt;/title&gt;    &lt;meta name=<span class="hljs-string">"keywords"</span> content=<span class="hljs-string">"SONY【PS4 Pro 国行主机】PlayStation 4 Pro 电脑娱乐游戏主机 1TB（黑色）2018版,索尼【PS4 Pro 国行主机】PlayStation 4 Pro 电脑娱乐游戏主机 1TB（黑色）2018版,索尼【PS4 Pro 国行主机】PlayStation 4 Pro 电脑娱乐游戏主机 1TB（黑色）2018版报价,SONY【PS4 Pro 国行主机】PlayStation 4 Pro 电脑娱乐游戏主机 1TB（黑色）2018版报价"</span>/&gt;    &lt;meta name=<span class="hljs-string">"description"</span> content=<span class="hljs-string">"【索尼【PS4 Pro 国行主机】PlayStation 4 Pro 电脑娱乐游戏主机 1TB（黑色）2018版】京东JD.COM提供索尼【PS4 Pro 国行主机】PlayStation 4 Pro 电脑娱乐游戏主机 1TB（黑色）2018版正品行货，并包括SONY【PS4 Pro 国行主机】PlayStation 4 Pro 电脑娱乐游戏主机 1TB（黑色）2018版网购指南，以及索尼【PS4 Pro 国行主机】PlayStation 4 Pro 电脑娱乐游戏主机 1TB（黑色）2018版图片、【PS4 Pro 国行主机】PlayStation 4 Pro 电脑娱乐游戏主机 1TB（黑色）2018版参数、【PS4 Pro 国行主机】PlayStation 4 Pro 电脑娱乐游戏主机 1TB（黑色）2018版评论、【PS4 Pro 国行主机】PlayStation 4 Pro 电脑娱乐游戏主机 1TB（黑色）2018版心得、</span></code></pre><p>&emsp;如果不设置headers，在爬取时则会反馈为京东登录页面，导致爬取失败。</p><pre><code class="hljs python">&lt;script&gt;window.location.href='https://passport.jd.com/uc/login?ReturnUrl=http%3A%2F%2Fitem.jd.com%2F100001484839.html'&lt;/script&gt;</code></pre><p>设置headers方法，以Chorm浏览器为例，随意点击一个页面，并刷新，按照下图操作，可以得到 ‘User-Agent’ 项属性，亦可以获得其它headers属性。<br><img src="https://img-blog.csdnimg.cn/20200812233116746.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>参考连接<br><a href="https://blog.csdn.net/ysblogs/article/details/88530124" target="_blank" rel="noopener">https://blog.csdn.net/ysblogs/article/details/88530124</a><br><a href="https://www.v2ex.com/t/540449" target="_blank" rel="noopener">https://www.v2ex.com/t/540449</a></p><h1 id="亚马逊商品页面爬取"><a href="#亚马逊商品页面爬取" class="headerlink" title="亚马逊商品页面爬取"></a>亚马逊商品页面爬取</h1><pre><code class="hljs python"><span class="hljs-comment">#亚马逊商品爬取</span><span class="hljs-keyword">import</span> requestsheader = &#123;        <span class="hljs-string">"Accept"</span>: <span class="hljs-string">"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9"</span>,        <span class="hljs-string">"Accept-Encoding"</span> : <span class="hljs-string">"gzip, deflate, br"</span>,        <span class="hljs-string">"Accept-Language"</span>: <span class="hljs-string">"zh-CN,zh;q=0.9"</span>,        <span class="hljs-string">"Cache-Control"</span>: <span class="hljs-string">"max-age=0"</span>,        <span class="hljs-string">"Connection"</span>: <span class="hljs-string">"keep-alive"</span>,        <span class="hljs-string">"Cookie"</span>: <span class="hljs-string">"BIDUPSID=A498E91CC6159D5E471FB9EF2A38F8D6; PSTM=1567500570; H_WISE_SIDS=127760_139203_122158_142080_141254_142208_142063_142112_135846_141003_138102_141862_138596_139090_141705_142174_142118_138878_137979_141200_140173_131246_137746_138165_107320_138883_140259_141838_140632_140201_139296_136863_138585_141650_140988_140113_131861_141743_140324_140578_133847_131423_140368_140965_136537_141103_110085_141941_127969_140593_140865_139887_140993_138426_138941_141190_141928; MCITY=-127%3A; BAIDUID=E913F916A8DF6B8C8E4CA4C1DC44C72E:FG=1; BDRCVFR[VXHUG3ZuJnT]=mk3SLVN4HKm; delPer=0; PSINO=3; BCLID=9107012877659863074; BDSFRCVID=hbtOJeCmHCVyVa7r-YsEeitoSeKK0gOTHllY6exBJok2qFDVJeC6EG0Ptf8g0Ku-Nb29ogKK0gOTH6KF_2uxOjjg8UtVJeC6EG0Ptf8g0M5; H_BDCLCKID_SF=fRPD_Dt5f-5_jJ7kqtbSMttfqx6betJyaR3IM56vWJ5TMC_wytQMW44XqJuDK4Q0bIOg0lv2Jq--ShPC-tnEDqKrDUobJfcBKCuOKn7v3l02Vb5Ie-t2ynQDebotqPRMW23UWl7mWIQvsxA45J7cM4IseboJLfT-0bc4KKJxbnLWeIJEjjCKD65LjN0ttTnfb5kX3R6qMJ7_KROkenrojM4pbt-qJJvPJebC-P_Eyx7GeJTmhpbcQUR-QpjnBT5KaaC8ahQ2WqRG8M3ab4ncbhKkQN3TbxuO5bRiLRolttF-Dn3oypJVXp0nj4Rly5jtMgOBBJ0yQ4b4OR5JjxonDh83bG7MJUutfJCj_C05tDIbbP365ITD-JIJ5fQ8-C62aKDsBno2BhcqEn6SLpjB34oWKmckbMQ-26nybb5cWKJJ8UbSh-vZj4LbL46ya5jD3enpaJ5nJq5nhMJmb67JDMP0qtTaJjcy523ion3vQpP-OpQ3DRoWXPIqbN7P-p5Z5mAqKl0MLPbtbb0xXj_0-nDSHHuJqx5; BDRCVFR[S4-dAuiWMmn]=xxDVat7Rueffj0znj01n1bsg1fzgv99; H_PS_PSSID=1467_32531_32356_32327_32045_32398_32090_32527_32482; BDORZ=B490B5EBF6F3CD402E515D22BCDA1598"</span>,        <span class="hljs-string">"Host"</span>: <span class="hljs-string">"baijiahao.baidu.com"</span>,        <span class="hljs-string">"Referer"</span>: <span class="hljs-string">"https://www.baidu.com/s?cl=3&amp;tn=baidutop10&amp;fr=top1000&amp;wd=%E5%AE%89%E5%BE%BD%E8%BF%9B%E5%8F%A3%E5%86%BB%E8%99%BE%E6%96%B0%E5%86%A0%E7%97%85%E6%AF%92%E6%A3%80%E5%87%BA%E9%98%B3%E6%80%A7&amp;rsv_idx=2&amp;rsv_dl=fyb_n_homepage&amp;hisfilter=1"</span>,        <span class="hljs-string">"Sec-Fetch-Dest"</span>: <span class="hljs-string">"document"</span>,        <span class="hljs-string">"Sec-Fetch-Mode"</span>: <span class="hljs-string">"navigate"</span>,        <span class="hljs-string">"Sec-Fetch-Site"</span>: <span class="hljs-string">"same-site"</span>,        <span class="hljs-string">"Sec-Fetch-User"</span>: <span class="hljs-string">"?1"</span>,        <span class="hljs-string">"User-Agent"</span>: <span class="hljs-string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36"</span>        &#125;<span class="hljs-comment">#此处需多种headers属性，单独"User-Agent"爬取内容失败</span><span class="hljs-comment"># url = "https://www.amazon.cn/dp/B081VWJG6N"</span><span class="hljs-comment"># try:</span><span class="hljs-comment">#     r = requests.get(url,headers = header)</span><span class="hljs-comment">#     print(r.status_code)</span><span class="hljs-comment">#     r.raise_for_status() #如果不是200，则产生异常requests.HTTPErrir</span><span class="hljs-comment">#     r.encoding =r.apparent_encoding #根据页面内容，采取编码</span><span class="hljs-comment">#     print(r.text[]) #因未作处理，故得到的数据未处理</span><span class="hljs-comment"># except:</span><span class="hljs-comment">#     print("连接异常")</span></code></pre><h1 id="搜索引擎关键词提交"><a href="#搜索引擎关键词提交" class="headerlink" title="搜索引擎关键词提交"></a>搜索引擎关键词提交</h1><p>重点为搜索引擎关键词的AP接口，此处也可以直接在”?“后面相加<br>360搜索引擎接口：<a href="http://www.so.com/s?q=keyword" target="_blank" rel="noopener">http://www.so.com/s?q=keyword</a><br>百度接口：<a href="http://www.baidu.com/s?wd=keyword" target="_blank" rel="noopener">http://www.baidu.com/s?wd=keyword</a></p><pre><code class="hljs python"><span class="hljs-keyword">import</span> requestsurl = <span class="hljs-string">"https://www.baidu.com/s"</span>  <span class="hljs-comment">#百度搜索引擎关键词提交接口</span>param = &#123;<span class="hljs-string">"wd"</span>:<span class="hljs-string">"123"</span>&#125;<span class="hljs-keyword">try</span>:    r = requests.get(url,headers= header,params= param)    print(r.status_code)    print(r.request.url)  <span class="hljs-comment">#可以显示发给百度的url到底是什么</span>    r.raise_for_status() <span class="hljs-comment">#如果不是200，则产生异常requests.HTTPErrir</span>    r.encoding =r.apparent_encoding <span class="hljs-comment">#根据页面内容，采取编码</span>    print(len(r.text))<span class="hljs-comment">#因未作处理，故得到的数据未处理</span><span class="hljs-keyword">except</span>:    print(<span class="hljs-string">"连接异常"</span>)</code></pre><pre><code class="hljs python"><span class="hljs-number">200</span>https://www.baidu.com/s?wd=123  #自动相加<span class="hljs-number">335573</span></code></pre><p>4：图片爬取和存储</p><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<span class="hljs-keyword">import</span> osurl  = <span class="hljs-string">"http://image.ngchina.com.cn/2020/0811/20200811031225371.jpg"</span>root = <span class="hljs-string">"D://pics//"</span>path = root + url.split(<span class="hljs-string">'/'</span>)[<span class="hljs-number">-1</span>]<span class="hljs-comment">#选中最后一部分内容</span><span class="hljs-keyword">try</span>:    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(root):        os.mkdir(root) <span class="hljs-comment">#如果不存在此路径，则创建此路径</span>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(path):        r = requests.get(url)        <span class="hljs-keyword">with</span> open(path,<span class="hljs-string">"wb"</span>) <span class="hljs-keyword">as</span> f:<span class="hljs-comment">#以二进制形式保存</span>            f.write(r.content)<span class="hljs-comment">#HTTP响应内容的二进制形式</span>            f.close()            print(<span class="hljs-string">"文件保存成功"</span>)    <span class="hljs-keyword">else</span>:        print(<span class="hljs-string">"文件已存在"</span>)<span class="hljs-keyword">except</span>:    print(<span class="hljs-string">"图片保存失败"</span>)</code></pre><h1 id="IP地址归属地查询"><a href="#IP地址归属地查询" class="headerlink" title="IP地址归属地查询"></a>IP地址归属地查询</h1><pre><code class="hljs python"><span class="hljs-keyword">import</span> requestsurl = <span class="hljs-string">'https://m.ip138.com/iplookup.asp?ip='</span>header = &#123;<span class="hljs-string">"User-Agent"</span>: <span class="hljs-string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36"</span>            &#125;<span class="hljs-comment">#此处若加其它属性，会报502的错误</span><span class="hljs-keyword">try</span>:    r = requests.get(url+<span class="hljs-string">"202.104.13.112"</span>,headers = header)    print(r.status_code)    r.raise_for_status() <span class="hljs-comment">#如果不是200，则产生异常requests.HTTPErrir</span>    r.encoding =r.apparent_encoding <span class="hljs-comment">#根据页面内容，采取编码</span>    print(r.text) <span class="hljs-comment">#因未作处理，故得到的数据未处理</span><span class="hljs-keyword">except</span>:    print(<span class="hljs-string">"连接异常"</span>)</code></pre>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>学习记录</tag>
      
      <tag>爬虫</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>初学爬虫（3）——爬虫风险和限制</title>
    <link href="/2020/08/10/%E5%88%9D%E5%AD%A6%E7%88%AC%E8%99%AB%EF%BC%883%EF%BC%89%E2%80%94%E2%80%94%E7%88%AC%E8%99%AB%E9%A3%8E%E9%99%A9%E5%92%8C%E9%99%90%E5%88%B6%EF%BC%8C%E7%AC%AC%E4%B8%89%E6%AC%A1%E6%8B%96%E5%88%B0%E6%9C%80%E5%90%8E/"/>
    <url>/2020/08/10/%E5%88%9D%E5%AD%A6%E7%88%AC%E8%99%AB%EF%BC%883%EF%BC%89%E2%80%94%E2%80%94%E7%88%AC%E8%99%AB%E9%A3%8E%E9%99%A9%E5%92%8C%E9%99%90%E5%88%B6%EF%BC%8C%E7%AC%AC%E4%B8%89%E6%AC%A1%E6%8B%96%E5%88%B0%E6%9C%80%E5%90%8E/</url>
    
    <content type="html"><![CDATA[<p>&emsp;这篇文章又是写在最后的时间，差不多也是一个单元的内容，这样速度有点慢了，下一篇为实战例子环节，争取明天写掉吧。</p><hr><h1 id="爬虫种类"><a href="#爬虫种类" class="headerlink" title="爬虫种类"></a>爬虫种类</h1><table><thead><tr><th>种类</th><th></th><th></th></tr></thead><tbody><tr><td>爬取网页 玩转网页</td><td>爬取网站 爬取系列网站</td><td>爬取全网</td></tr><tr><td>小规模，数据量小</td><td>中规模，数据规模较大</td><td>大规模，搜索引擎</td></tr><tr><td>爬取速度不敏感</td><td>爬取速度敏感</td><td>爬取速度关键</td></tr><tr><td>Requests库，大于90%</td><td>Scrapy库</td><td>定制开发，例如百度，谷歌</td></tr></tbody></table><h1 id="爬虫风险"><a href="#爬虫风险" class="headerlink" title="爬虫风险"></a>爬虫风险</h1><h2 id="爬虫对网站服务器的“性能骚扰”"><a href="#爬虫对网站服务器的“性能骚扰”" class="headerlink" title="爬虫对网站服务器的“性能骚扰”"></a>爬虫对网站服务器的“性能骚扰”</h2><p>Web服务器默认接收人类访问<br>受限于编写水平和目的，网络爬虫将会为Web服务器带来巨大的资源开销<br>爬虫可以以人类百倍乃至千倍的速度访问网站，给网站带来超量负担</p><h2 id="爬虫的“法律风险”"><a href="#爬虫的“法律风险”" class="headerlink" title="爬虫的“法律风险”"></a>爬虫的“法律风险”</h2><p>服务器的数据有产权归属，当爬虫获取这些数据并以此牟利时，将带来法律风险</p><h2 id="网络爬虫的隐私泄露"><a href="#网络爬虫的隐私泄露" class="headerlink" title="网络爬虫的隐私泄露"></a>网络爬虫的隐私泄露</h2><p>网络爬虫可能具备突破简单访问控制的能力，获得被保护数据，从而泄露个人隐私。</p><h1 id="网络爬虫的限制"><a href="#网络爬虫的限制" class="headerlink" title="网络爬虫的限制"></a>网络爬虫的限制</h1><h2 id="来源审查"><a href="#来源审查" class="headerlink" title="来源审查"></a>来源审查</h2><p>判断User‐Agent进行限制<br>检查来访HTTP协议头的User‐Agent域，只响应浏览器或友好爬虫的访问<br>只响应一定范围内的访问，超出此范围，则判定为恶意爬虫，不做响应。<br>此方法有一定的技术要求</p><h2 id="发布公告：Robots协议"><a href="#发布公告：Robots协议" class="headerlink" title="发布公告：Robots协议"></a>发布公告：Robots协议</h2><p>类似于公告板<br>告知所有爬虫网站的爬取策略，要求爬虫遵守<br>仅仅只是发布，是否遵守由网络爬虫自身决定。</p><h1 id="Robots协议"><a href="#Robots协议" class="headerlink" title="Robots协议"></a>Robots协议</h1><p>Robots Exclusion Standard，网络爬虫排除标准，可称为Robots.txt</p><p>网站通过Robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取。<br>Robots的用法有两种：<br>1：告诉搜索引擎哪些页面你不能抓（默认其他的就可以抓）<br>2：告诉搜索引擎你只能抓取哪些页面（默认其他的不可以抓）</p><p>在网站根目录下的robots.txt文件（注：小写），形式类似于以下举例。</p><h2 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h2><p><a href="https://www.jd.com/robots.txt" target="_blank" rel="noopener">京东Robots协议</a></p><pre><code class="hljs html">User-agent: *    #对于任意来源网络爬虫，都应遵守以下协议Disallow: /?*    #任何爬虫都不允许访问以 ?* 开头的路径Disallow: /pop/*.html  #任何爬虫都不允许访问符合pop/*.html 的路径Disallow: /pinpai/*.html?* #不允许访问符合pinpai/*.html?*  的路径User-agent: EtaoSpider  #对于以下四种爬虫，禁止访问任何京东页面Disallow: / User-agent: HuihuiSpider Disallow: / User-agent: GwdangSpider Disallow: / User-agent: WochachaSpider Disallow: /</code></pre><p>其它例子：<br>百度：<a href="http://www.baidu.com/robots.txt" target="_blank" rel="noopener">http://www.baidu.com/robots.txt</a><br>新浪：<a href="http://news.sina.com.cn/robots.txt" target="_blank" rel="noopener">http://news.sina.com.cn/robots.txt</a><br>QQ：<a href="http://www.qq.com/robots.txt" target="_blank" rel="noopener">http://www.qq.com/robots.txt</a><br>QQ新闻：<a href="http://news.qq.com/robots.txt" target="_blank" rel="noopener">http://news.qq.com/robots.txt</a><br>教育部网站：<a href="http://www.moe.edu.cn/robots.txt" target="_blank" rel="noopener">http://www.moe.edu.cn/robots.txt</a> （无robots协议）<br>如果一个网站没有robots.txt文件，则代表这个网站允许所有爬虫无限制爬取内容</p><h2 id="Robots协议基本语法"><a href="#Robots协议基本语法" class="headerlink" title="Robots协议基本语法"></a>Robots协议基本语法</h2><pre><code class="hljs html"># 注释，*代表所有，/代表根目录User‐agent: *  #代表哪些爬虫Disallow: /    #不允许这些爬虫访问资源目录</code></pre><p>或</p><pre><code class="hljs html">User‐agent: *  #代表哪些爬虫Allow:允许的目录或文件</code></pre><p>robots.txt文件详解<br><a href="http://blog.sina.com.cn/s/blog_68e95e7d0100rjfh.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_68e95e7d0100rjfh.html</a></p><h2 id="Robots-txt协议遵守方式"><a href="#Robots-txt协议遵守方式" class="headerlink" title="Robots.txt协议遵守方式"></a>Robots.txt协议遵守方式</h2><p>网络爬虫：<br>自动或人工识别robots.txt，再进行内容爬取<br>可以人工根据协议编写爬虫，也可以自动识别协议后限制爬虫<br><strong>约束性：</strong><br>Robots协议是建议但非约束性，网络爬虫可以不遵守，但存在法律风险</p><table><thead><tr><th>种类</th><th></th><th></th></tr></thead><tbody><tr><td>访问量很小：可以遵守，访问量较大：建议遵守</td><td>非商业且偶尔：建议遵守，商业利益：必须遵守</td><td>爬取全网</td></tr><tr><td>玩转网页 爬取网页</td><td>爬取网站  爬取系列网站</td><td>必须遵守</td></tr><tr><td>原则：类人行为可不参考Robots协议</td><td></td><td></td></tr><tr><td>类人行为：服务器访问次数较少，并对服务器不造成巨大资源影响的爬虫，因这种爬虫和人类访问网页相差不大，故可不参考Robots协议</td><td></td><td></td></tr></tbody></table><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="各大常用搜索引擎爬虫"><a href="#各大常用搜索引擎爬虫" class="headerlink" title="各大常用搜索引擎爬虫"></a>各大常用搜索引擎爬虫</h2><p><strong><em>注：蜘蛛名称区分大小写</em></strong></p><p>百度：Baiduspider<br>360：360Spider<br>搜狗：Sogou News Spider（不止）<br>有道：YoudaoBot，YodaoBot<br>谷歌：GoogleBot（不止）<br>雅虎：yahoo-slurp</p><p>参考：<br>1.<a href="https://www.cnblogs.com/cocowool/p/5002546.html" target="_blank" rel="noopener">https://www.cnblogs.com/cocowool/p/5002546.html</a><br>2.<a href="https://blog.csdn.net/weixin_44711613/article/details/88076847" target="_blank" rel="noopener">https://blog.csdn.net/weixin_44711613/article/details/88076847</a></p><h2 id="自动生成robots-txt"><a href="#自动生成robots-txt" class="headerlink" title="自动生成robots.txt"></a>自动生成robots.txt</h2><p><a href="https://robots.51240.com/" target="_blank" rel="noopener">https://robots.51240.com/</a></p>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>学习记录</tag>
      
      <tag>爬虫</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>初学爬虫（2）——Requests库基础，险些打脸</title>
    <link href="/2020/08/08/%E5%88%9D%E5%AD%A6%E7%88%AC%E8%99%AB%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94Requests%E5%BA%93%E5%9F%BA%E7%A1%80%EF%BC%8C%E9%99%A9%E4%BA%9B%E6%89%93%E8%84%B8/"/>
    <url>/2020/08/08/%E5%88%9D%E5%AD%A6%E7%88%AC%E8%99%AB%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94Requests%E5%BA%93%E5%9F%BA%E7%A1%80%EF%BC%8C%E9%99%A9%E4%BA%9B%E6%89%93%E8%84%B8/</url>
    
    <content type="html"><![CDATA[<p>&emsp;写在前面，这是爬虫的第二篇学习记录，虽然是把已经之前已经学过的内容搬过来整理了一下 ，但还是险些被打脸，两天一篇的目标，还是自己太懒了，这次凑合过了两天，后天就要下一篇了，自己立的Flag，熬夜都得搞完——8月8日晚上0：45<br>———————————————————————————————————————————<br>&emsp;Requests库是目前python公认的爬取网页的最好的第三方库之一，可以，也是实现爬虫的基础库之一。<br>在<a href="https://requests.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">Request库官网（中文）</a>上，首先便是这样一段内容：  </p><p>Requests 唯一的一个非转基因的 Python HTTP 库，人类可以安全享用。<br>警告：非专业使用其他HTTP库会导致危险的副作用，包括：安全缺陷症、冗余代码症、重新发明轮子症、啃文档症、抑郁、头疼、甚至死亡。</p><p>看吧，这就是 Requests 的威力：</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.get(<span class="hljs-string">'https://api.github.com/user'</span>, auth=(<span class="hljs-string">'user'</span>, <span class="hljs-string">'pass'</span>))<span class="hljs-meta">&gt;&gt;&gt; </span>r.status_code<span class="hljs-number">200</span><span class="hljs-meta">&gt;&gt;&gt; </span>r.headers[<span class="hljs-string">'content-type'</span>]<span class="hljs-string">'application/json; charset=utf8'</span><span class="hljs-meta">&gt;&gt;&gt; </span>r.encoding<span class="hljs-string">'utf-8'</span><span class="hljs-meta">&gt;&gt;&gt; </span>r.text<span class="hljs-string">u'&#123;"type":"User"...'</span><span class="hljs-meta">&gt;&gt;&gt; </span>r.json()&#123;<span class="hljs-string">u'private_gists'</span>: <span class="hljs-number">419</span>, <span class="hljs-string">u'total_private_repos'</span>: <span class="hljs-number">77</span>, ...&#125;</code></pre><p>Requests 允许你发送纯天然，植物饲养的 HTTP/1.1 请求，无需手工劳动。你不需要手动为 URL 添加查询字串，也不需要对 POST 数据进行表单编码。Keep-alive 和 HTTP 连接池的功能是 100% 自动化的，一切动力都来自于根植在 Requests 内部的 urllib3。<br>当我第一次看到这段时，感觉是这样的。</p><p><img src="https://img-blog.csdnimg.cn/20200807215947225.png" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><h1 id="HTTP协议"><a href="#HTTP协议" class="headerlink" title="HTTP协议"></a>HTTP协议</h1><p>首先在说明Request库之前，我们需要先了解一些关于HTTP协议的相关知识，这对应着Request库的基本方法原理。<br>HTTP，Hypertext Transfer Protocol，超文本传输协议<br>HTTP是一个基于“请求与响应”模式的、无状态的应用层协议<br>简单的说，用户发起请求，服务器作出响应，这就是“请求与响应模式”，无状态则指用户发起的这一次请求和上一次请求之间没有关联，应用层则是指该协议工作在TCP协议之上。<br>HTTP协议采用URL作为定位网络资源的标识，URL格式如下：  </p><pre><code class="hljs markdown">http://host[<span class="hljs-string">:port</span>][<span class="hljs-symbol">path</span>]</code></pre><p>host: 合法的Internet主机域名或IP地址<br>port: 端口号，缺省端口为80，这部分可以省略<br>path: 请求资源的路径<br>HTTP URL实例：  </p><pre><code class="hljs dts"><span class="hljs-symbol">http:</span><span class="hljs-comment">//www.bit.edu.cn </span><span class="hljs-symbol">http:</span><span class="hljs-comment">//220.181.111.188/duty</span></code></pre><p>HTTP URL的理解：<br>URL是通过HTTP协议存取资源的Internet路径，一个URL对应一个数据资源<br>HTTO协议对资源最主要的操作有六个：</p><table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>GET</td><td>请求获取URL位置的资源</td></tr><tr><td>HEAD</td><td>请求获取URL位置资源的响应消息报告，即获得该资源的头部信息</td></tr><tr><td>POST</td><td>请求向URL位置的资源后附加新的数据</td></tr><tr><td>URL</td><td>请求向URL位置存储一个资源，覆盖原URL位置的资源</td></tr><tr><td>PATCH</td><td>请求局部更新URL位置的资源，即改变该处资源的部分内容</td></tr><tr><td>DELETE</td><td>请求删除URL位置存储的资源</td></tr></tbody></table><p>关于PATCH和PUT方法的区别：<br>假设有一组资源为Userinfo，包含UserName，UserID等20个字段，<br>需求：改变UserName，其它不变<br>采用PATCH，只需改变UserName，其它无需操作，可以节省网络带宽，防止修改过度。即可以部分改变。<br>采用PUT，需要将包括UserName，UserID等20个字段一起提交，未提交字段将被删除。即必须整体改变。<br><img src="https://img-blog.csdnimg.cn/20200807223812717.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>如果需要获取资源，可以采用GET，HEAD方法<br>如果需要上传或改变资源，则可以用PUT，POST，PATCH<br>如果需要删除资源，则可以使用DELETE<br>HTTP协议通过URL定位资源，通过这六个命令管理资源，每一次操作均为独立且无状态的。</p><h1 id="Requests库基本方法"><a href="#Requests库基本方法" class="headerlink" title="Requests库基本方法"></a>Requests库基本方法</h1><p>Requests共有7个主要方法：<br>方法| 说明<br>—|—<br>requests.request() |构造一个请求，支撑以下各方法的基础方法<br>requests.get() |获取HTML网页的主要方法，对应于HTTP的GET<br>requests.head()| 获取HTML网页头信息的方法，对应于HTTP的HEAD<br>requests.post() |向HTML网页提交POST请求的方法，对应于HTTP的POST<br>requests.put()| 向HTML网页提交PUT请求的方法，对应于HTTP的PUT<br>requests.patch()| 向HTML网页提交局部修改请求，对应于HTTP的PATCH<br>requests.delete()| 向HTML页面提交删除请求，对应于HTTP的DELETE<br>其中六种方法对应于HTTP协议的六种基本操作：<br>HTTP协议方法|Requests库方法|功能一致性<br>—|——|—|<br>GET |requests.get() |一致<br>HEAD| requests.head() |一致<br>POST |requests.post()| 一致<br>PUT |requests.put() |一致<br>PATCH| requests.patch() |一致<br>DELETE| requests.delete()| 一致</p><p>以下为各方法的解析：</p><h2 id="requests-request-——Requests库最基本方法"><a href="#requests-request-——Requests库最基本方法" class="headerlink" title="requests.request()——Requests库最基本方法"></a>requests.request()——Requests库最基本方法</h2><p>最基础的一个方法，其它六个方法均用此方法封装<br><strong>***requests.request(method,url,</strong>kwargs)*****</p><p><strong>method：请求方式，对应于HTTP协议和Requests库的六种基本操作（方法）</strong><br>r = requests.request(‘GET’, url, *<em>kwargs)<br>r = requests.request(‘HEAD’, url, *</em>kwargs)<br>r = requests.request(‘POST’, url, *<em>kwargs)<br>r = requests.request(‘PUT’, url, *</em>kwargs)<br>r = requests.request(‘PATCH’, url, *<em>kwargs)<br>r = requests.request(‘delete’, url, *</em>kwargs)<br>r = requests.request(‘OPTIONS’, url, **kwargs)</p><p><strong>url：访问的url地址，链接</strong></p><p><strong>**kwargs：13个可选的控制参数：</strong><br>[1]:params : 字典或字节序列，作为参数增加到url中。即可以在访问链接时，带一些参数访问</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>kv = &#123;<span class="hljs-string">'key1'</span>: <span class="hljs-string">'value1'</span>, <span class="hljs-string">'key2'</span>: <span class="hljs-string">'value2'</span>&#125;<span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.request(<span class="hljs-string">'GET'</span>, <span class="hljs-string">'http://python123.io/ws'</span>, params=kv)<span class="hljs-meta">&gt;&gt;&gt; </span>print(r.url)http://python123.io/ws?key1=value1&amp;key2=value2</code></pre><p>[2]data : 字典、字节序列或文件对象，作为Request的内容。提交资源，向url所对应位置作为数据存储。</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>kv = &#123;<span class="hljs-string">'key1'</span>: <span class="hljs-string">'value1'</span>, <span class="hljs-string">'key2'</span>: <span class="hljs-string">'value2'</span>&#125;<span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.request(<span class="hljs-string">'POST'</span>, <span class="hljs-string">'http://python123.io/ws'</span>, data=kv)<span class="hljs-meta">&gt;&gt;&gt; </span>body = <span class="hljs-string">'主体内容'</span><span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.request(<span class="hljs-string">'POST'</span>, <span class="hljs-string">'http://python123.io/ws'</span>, data=body)</code></pre><p>[3]json : JSON格式的数据，作为Request的内容，同上，向服务器提交资源的参数。</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>kv = &#123;<span class="hljs-string">'key1'</span>: <span class="hljs-string">'value1'</span>&#125;<span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.request(<span class="hljs-string">'POST'</span>, <span class="hljs-string">'http://python123.io/ws'</span>, json=kv)</code></pre><p>[4]headers : 字典，HTTP定制头，head对应于向url字段发起Http请求时的头字段，可以定制访问url的协议头。</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>hd = &#123;<span class="hljs-string">'user‐agent'</span>: <span class="hljs-string">'Chrome/10'</span>&#125;<span class="hljs-comment">#模拟Chrom浏览器10.0来访问url，可以替换成任意浏览器。</span><span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.request(<span class="hljs-string">'POST'</span>, <span class="hljs-string">'http://python123.io/ws'</span>, headers=hd)</code></pre><p>[5]cookies : 字典或CookieJar，Request中的cookie。<br>[6]auth : 元组，支持HTTP认证功能。<br>[7[files : 字典类型，传输文件。同data，json，不过提交的是文件内容。</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>fs = &#123;<span class="hljs-string">'file'</span>: open(<span class="hljs-string">'data.xls'</span>, <span class="hljs-string">'rb'</span>)&#125;<span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.request(<span class="hljs-string">'POST'</span>, <span class="hljs-string">'http://python123.io/ws'</span>, files=fs)</code></pre><p>[8]timeout : 设定超时时间，秒为单位。当超过限制时间时，将会报出异常。</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.request(<span class="hljs-string">'GET'</span>, <span class="hljs-string">'http://www.baidu.com'</span>, timeout=<span class="hljs-number">10</span>)</code></pre><p>[9]proxies : 字典类型，设定访问代理服务器，可以增加登录认证。</p><pre><code class="hljs python"><span class="hljs-comment">#此处增加两个代理，</span><span class="hljs-comment">#http访问代理，可以增加访问的用户名和密码设置</span><span class="hljs-comment">#https代理，当访问url时，所使用的IP地址为代理服务器地址，可以隐藏访问的原IP地址，可以有效防止对爬虫的逆追踪。</span><span class="hljs-meta">&gt;&gt;&gt; </span>pxs = &#123; <span class="hljs-string">'http'</span>: <span class="hljs-string">'http://user:pass@10.10.10.1:1234'</span><span class="hljs-string">'https'</span>: <span class="hljs-string">'https://10.10.10.1:4321'</span> &#125; <span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.request(<span class="hljs-string">'GET'</span>, <span class="hljs-string">'http://www.baidu.com'</span>, proxies=pxs)</code></pre><p>[10]allow_redirects : True/False，默认为True，重定向开关。表示允不允许对url进行重定向。<br>[11]stream : True/False，默认为True，获取内容立即下载开关。指对获取的内容是否立即下载。<br>[12]verify : True/False，默认为True，认证SSL证书开关。<br>[13]cert : 保存本地SSL证书路径。</p><table><thead><tr><th>可选参数</th><th>说明</th></tr></thead><tbody><tr><td>params</td><td>字典或字节序列，作为参数增加到url中。即可以在访问链接时，带一些参数访问</td></tr><tr><td>data</td><td>字典、字节序列或文件对象，作为Request的内容。提交资源，向url所对应位置作为数据存储。</td></tr><tr><td>json</td><td>JSON格式的数据，作为Request的内容，同上，向服务器提交资源的参数。</td></tr><tr><td>headers</td><td>字典，HTTP定制头，head对应于向url字段发起Http请求时的头字段，可以定制访问url的协议头。</td></tr><tr><td>cookies</td><td>字典或CookieJar，Request中的cookie</td></tr><tr><td>auth</td><td>元组，支持HTTP认证功能</td></tr><tr><td>files</td><td>字典类型，传输文件。同data，json，不过提交的是文件内容</td></tr><tr><td>timeout</td><td>设定超时时间，秒为单位。当超过限制时间时，将会报出异常。</td></tr><tr><td>proxies</td><td>字典类型，设定访问代理服务器，可以增加登录认证。</td></tr><tr><td>allow_redirects</td><td>True/False，默认为True，重定向开关。表示允不允许对url进行重定向。</td></tr><tr><td>stream</td><td>True/False，默认为True，获取内容立即下载开关。指对获取的内容是否立即下载。</td></tr><tr><td>verify</td><td>True/False，默认为True，认证SSL证书开关。</td></tr><tr><td>cert</td><td>保存本地SSL证书路径。</td></tr><tr><td>ps：此处参数也对应于其它六种基本方法</td><td></td></tr></tbody></table><h2 id="requests-get"><a href="#requests-get" class="headerlink" title="requests.get()"></a>requests.get()</h2><p>requests.get(url, params=None, *<em>kwargs)<br>url:获得页面的url链接<br>params:url中的额外参数，字典或字节流格式，可选<br>*</em>kwargs:其它12种可选参数</p><pre><code class="hljs python">r=requests.get(url)<span class="hljs-comment">#get方法构造了一个向服务器请求资源的Request对象</span><span class="hljs-comment">#r为返回一个包含服务器所有资源的Response对象</span></code></pre><p><strong>Response对象</strong><br>包含了爬虫返回的内容</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> requests<span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.get(<span class="hljs-string">"http://www.baidu.com"</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>print(r.status_code)<span class="hljs-number">200</span>  <span class="hljs-comment">#说明访问成功</span><span class="hljs-meta">&gt;&gt;&gt; </span>type(r)<span class="hljs-comment">#Response对象</span>&lt;<span class="hljs-class"><span class="hljs-keyword">class</span> '<span class="hljs-title">requests</span>.<span class="hljs-title">models</span>.<span class="hljs-title">Response</span>'&gt;</span><span class="hljs-class">&gt;&gt;&gt; <span class="hljs-title">r</span>.<span class="hljs-title">headers</span></span>&#123;'Cache-Control': 'private, no-cache, no-store, proxy-revalidate, no-transform', 'Connection': 'keep-alive', 'Content-Encoding': 'gzip', 'Content-Type': 'text/html', 'Date': 'Fri, 07 Aug 2020 15:54:47 GMT', 'Last-Modified': 'Mon, 23 Jan 2017 13:28:16 GMT', 'Pragma': 'no-cache', 'Server': 'bfe/1.0.8.18', 'Set-Cookie': 'BDORZ=27315; max-age=86400; domain=.baidu.com; path=/', 'Transfer-Encoding': 'chunked'&#125;</code></pre><p>Response对象属性<br>属性|说明<br>—|–|<br>r.status_code| HTTP请求的返回状态，200表示连接成功，404表示失败<br>r.text HTTP|响应内容的字符串形式，即，url对应的页面内容<br>r.encoding |从HTTP header中猜测的响应内容编码方式<br>r.apparent_encoding |从内容中分析出的响应内容编码方式（备选编码方式）<br>r.content HTTP|响应内容的二进制形式</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.get(<span class="hljs-string">"http://www.baidu.com"</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>r.status_code<span class="hljs-number">200</span><span class="hljs-meta">&gt;&gt;&gt; </span>print(r)&lt;Response [<span class="hljs-number">200</span>]&gt;<span class="hljs-meta">&gt;&gt;&gt; </span>r.text<span class="hljs-string">'&lt;!DOCTYPE html&gt;\r\n&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;ç\x99¾åº¦ä¸\x80ä¸\x8bï¼\x8cä½\xa0å°±ç\x9f¥é\x81\x93&lt;/title&gt;&lt;/head&gt; &lt;body link=#0000cc&gt; &lt;div id=wrapper&gt; &lt;div id=head&gt; &lt;div class=head_wrapper&gt; &lt;div class=s_form&gt; &lt;div class=s_form_wrapper&gt; &lt;div id=lg&gt; &lt;img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129&gt; &lt;/div&gt; &lt;form id=form name=f action=//www.baidu.com/s class=fm&gt; &lt;input type=hidden name=bdorz_come value=1&gt; &lt;input type=hidden name=ie value=utf-8&gt; &lt;input type=hidden name=f value=8&gt; &lt;input type=hidden name=rsv_bp value=1&gt; &lt;input type=hidden name=rsv_idx value=1&gt; &lt;input type=hidden name=tn value=baidu&gt;&lt;span class="bg s_ipt_wr"&gt;&lt;input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus&gt;&lt;/span&gt;&lt;span class="bg s_btn_wr"&gt;&lt;input type=submit id=su value=ç\x99¾åº¦ä¸\x80ä¸\x8b class="bg s_btn"&gt;&lt;/span&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=u1&gt; &lt;a href=http://news.baidu.com name=tj_trnews class=mnav&gt;æ\x96°é\x97»&lt;/a&gt; &lt;a href=http://www.hao123.com name=tj_trhao123 class=mnav&gt;hao123&lt;/a&gt; &lt;a href=http://map.baidu.com name=tj_trmap class=mnav&gt;å\x9c°å\x9b¾&lt;/a&gt; &lt;a href=http://v.baidu.com name=tj_trvideo class=mnav&gt;è§\x86é¢\x91&lt;/a&gt; &lt;a href=http://tieba.baidu.com name=tj_trtieba class=mnav&gt;è´´å\x90§&lt;/a&gt; &lt;noscript&gt; &lt;a href=http://www.baidu.com/bdorz/login.gif?login&amp;amp;tpl=mn&amp;amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb&gt;ç\x99»å½\x95&lt;/a&gt; &lt;/noscript&gt; &lt;script&gt;document.write(\'&lt;a href="http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=\'+ encodeURIComponent(window.location.href+ (window.location.search === "" ? "?" : "&amp;")+ "bdorz_come=1")+ \'" name="tj_login" class="lb"&gt;ç\x99»å½\x95&lt;/a&gt;\');&lt;/script&gt; &lt;a href=//www.baidu.com/more/ name=tj_briicon class=bri style="display: block;"&gt;æ\x9b´å¤\x9aäº§å\x93\x81&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=ftCon&gt; &lt;div id=ftConw&gt; &lt;p id=lh&gt; &lt;a href=http://home.baidu.com&gt;å\x85³äº\x8eç\x99¾åº¦&lt;/a&gt; &lt;a href=http://ir.baidu.com&gt;About Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id=cp&gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&lt;a href=http://www.baidu.com/duty/&gt;ä½¿ç\x94¨ç\x99¾åº¦å\x89\x8då¿\x85è¯»&lt;/a&gt;&amp;nbsp; &lt;a href=http://jianyi.baidu.com/ class=cp-feedback&gt;æ\x84\x8fè§\x81å\x8f\x8dé¦\x88&lt;/a&gt;&amp;nbsp;äº¬ICPè¯\x81030173å\x8f·&amp;nbsp; &lt;img src=//www.baidu.com/img/gs.gif&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;\r\n'</span><span class="hljs-meta">&gt;&gt;&gt; </span>r.encoding <span class="hljs-comment">#如果header中不存在chareset，则认为编码为'ISO-8859-1'</span><span class="hljs-string">'ISO-8859-1'</span><span class="hljs-meta">&gt;&gt;&gt; </span>r.apparent_encoding <span class="hljs-comment">#根据网页内容分析出的编码方式</span><span class="hljs-string">'utf-8'</span><span class="hljs-meta">&gt;&gt;&gt; </span>r.encoding = <span class="hljs-string">'utf-8'</span> <span class="hljs-comment">#r.apparent_encoding</span><span class="hljs-meta">&gt;&gt;&gt; </span>r.text<span class="hljs-string">'&lt;!DOCTYPE html&gt;\r\n&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;百度一下，你就知道&lt;/title&gt;&lt;/head&gt; &lt;body link=#0000cc&gt; &lt;div id=wrapper&gt; &lt;div id=head&gt; &lt;div class=head_wrapper&gt; &lt;div class=s_form&gt; &lt;div class=s_form_wrapper&gt; &lt;div id=lg&gt; &lt;img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129&gt; &lt;/div&gt; &lt;form id=form name=f action=//www.baidu.com/s class=fm&gt; &lt;input type=hidden name=bdorz_come value=1&gt; &lt;input type=hidden name=ie value=utf-8&gt; &lt;input type=hidden name=f value=8&gt; &lt;input type=hidden name=rsv_bp value=1&gt; &lt;input type=hidden name=rsv_idx value=1&gt; &lt;input type=hidden name=tn value=baidu&gt;&lt;span class="bg s_ipt_wr"&gt;&lt;input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus&gt;&lt;/span&gt;&lt;span class="bg s_btn_wr"&gt;&lt;input type=submit id=su value=百度一下 class="bg s_btn"&gt;&lt;/span&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=u1&gt; &lt;a href=http://news.baidu.com name=tj_trnews class=mnav&gt;新闻&lt;/a&gt; &lt;a href=http://www.hao123.com name=tj_trhao123 class=mnav&gt;hao123&lt;/a&gt; &lt;a href=http://map.baidu.com name=tj_trmap class=mnav&gt;地图&lt;/a&gt; &lt;a href=http://v.baidu.com name=tj_trvideo class=mnav&gt;视频&lt;/a&gt; &lt;a href=http://tieba.baidu.com name=tj_trtieba class=mnav&gt;贴吧&lt;/a&gt; &lt;noscript&gt; &lt;a href=http://www.baidu.com/bdorz/login.gif?login&amp;amp;tpl=mn&amp;amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb&gt;登录&lt;/a&gt; &lt;/noscript&gt; &lt;script&gt;document.write(\'&lt;a href="http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=\'+ encodeURIComponent(window.location.href+ (window.location.search === "" ? "?" : "&amp;")+ "bdorz_come=1")+ \'" name="tj_login" class="lb"&gt;登录&lt;/a&gt;\');&lt;/script&gt; &lt;a href=//www.baidu.com/more/ name=tj_briicon class=bri style="display: block;"&gt;更多产品&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=ftCon&gt; &lt;div id=ftConw&gt; &lt;p id=lh&gt; &lt;a href=http://home.baidu.com&gt;关于百度&lt;/a&gt; &lt;a href=http://ir.baidu.com&gt;About Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id=cp&gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&lt;a href=http://www.baidu.com/duty/&gt;使用百度前必读&lt;/a&gt;&amp;nbsp; &lt;a href=http://jianyi.baidu.com/ class=cp-feedback&gt;意见反馈&lt;/a&gt;&amp;nbsp;京ICP证030173号&amp;nbsp; &lt;img src=//www.baidu.com/img/gs.gif&gt; &lt;/p&gt; &lt;/d</span></code></pre><p>r.encoding：如果header中不存在charset，则认为编码为ISO‐8859‐1。<br>r.text：根据r.encoding显示网页内容。<br>r.apparent_encoding：根据网页内容分析出的编码方式，可以看作是r.encoding的备选，可以直接使用这个编码方式，理论上来说比r.encoding更准确。</p><pre><code class="hljs python">r.encoding = r.apparent_encoding <span class="hljs-comment">#类似于这样</span></code></pre><p>requests.get()的基础步骤</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.get(<span class="hljs-string">"http://www.baidu.com"</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>r.status_code<span class="hljs-number">200</span><span class="hljs-comment">#说明访问成功，如果是404或其它，则说明产生了异常</span><span class="hljs-comment">#如果成功访问，则可以使用以下属性查看解析内容</span>r.text r.encodingr.apparent_encodingr.content</code></pre><h2 id="requests-head"><a href="#requests-head" class="headerlink" title="requests.head()"></a>requests.head()</h2><p>反馈url链接的头部链接，可以节省带宽，获得概要信息<br>requests.head(url, *<em>kwargs)<br>url : 拟获取页面的url链接<br>*</em>kwargs: 12个控制访问的参数</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> requests<span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.head(<span class="hljs-string">'http://httpbin.org/get'</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>r.headers&#123;<span class="hljs-string">'Date'</span>: <span class="hljs-string">'Fri, 07 Aug 2020 16:16:12 GMT'</span>, <span class="hljs-string">'Content-Type'</span>: <span class="hljs-string">'application/json'</span>, <span class="hljs-string">'Content-Length'</span>: <span class="hljs-string">'306'</span>, <span class="hljs-string">'Connection'</span>: <span class="hljs-string">'keep-alive'</span>, <span class="hljs-string">'Server'</span>: <span class="hljs-string">'gunicorn/19.9.0'</span>, <span class="hljs-string">'Access-Control-Allow-Origin'</span>: <span class="hljs-string">'*'</span>, <span class="hljs-string">'Access-Control-Allow-Credentials'</span>: <span class="hljs-string">'true'</span>&#125;<span class="hljs-meta">&gt;&gt;&gt; </span>r.text<span class="hljs-string">''</span></code></pre><h2 id="requests-post"><a href="#requests-post" class="headerlink" title="requests.post()"></a>requests.post()</h2><p>requests.post(url, data=None, json=None, *<em>kwargs)<br>url : 拟更新页面的url链接<br>data : 字典、字节序列或文件，Request的内容<br>json : JSON格式的数据，Request的内容<br>*</em>kwargs: 11个控制访问的参数<br>根据用户提交内容的不同，在服务器上会做相关数据处理<br>向url post一个字典，自动编码为form（表单）</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>payload = &#123;<span class="hljs-string">'key1'</span>: <span class="hljs-string">'value1'</span>, <span class="hljs-string">'key2'</span>: <span class="hljs-string">'value2'</span>&#125;<span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.post(<span class="hljs-string">'http://httpbin.org/post'</span>, data = payload)<span class="hljs-meta">&gt;&gt;&gt; </span>print(r.text)&#123; ...<span class="hljs-string">"form"</span>: &#123;<span class="hljs-string">"key2"</span>: <span class="hljs-string">"value2"</span>,<span class="hljs-string">"key1"</span>: <span class="hljs-string">"value1"</span>&#125;,&#125;</code></pre><p>向url post一个字符串，自动编码为data（表单）</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.post(<span class="hljs-string">'http://httpbin.org/post'</span>, data = <span class="hljs-string">'ABC'</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>print(r.text)&#123; ...<span class="hljs-string">"data"</span>: <span class="hljs-string">"ABC"</span><span class="hljs-string">"form"</span>: &#123;&#125;,&#125;</code></pre><h2 id="requests-put"><a href="#requests-put" class="headerlink" title="requests.put()"></a>requests.put()</h2><p>同post方法，不过可以将原来数据覆盖掉<br>requests.put(url, data=None, *<em>kwargs)<br>∙ url : 拟更新页面的url链接<br>∙ data : 字典、字节序列或文件，Request的内容<br>∙ *</em>kwargs: 12个控制访问的参数</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>payload = &#123;<span class="hljs-string">'key1'</span>: <span class="hljs-string">'value1'</span>, <span class="hljs-string">'key2'</span>: <span class="hljs-string">'value2'</span>&#125;<span class="hljs-meta">&gt;&gt;&gt; </span>r = requests.put(<span class="hljs-string">'http://httpbin.org/put'</span>, data = payload)<span class="hljs-meta">&gt;&gt;&gt; </span>print(r.text)&#123; ...<span class="hljs-string">"form"</span>: &#123;<span class="hljs-string">"key2"</span>: <span class="hljs-string">"value2"</span>,<span class="hljs-string">"key1"</span>: <span class="hljs-string">"value1"</span>&#125;,&#125;</code></pre><h2 id="requests-patch"><a href="#requests-patch" class="headerlink" title="requests.patch()"></a>requests.patch()</h2><p>requests.patch(url, data=None, *<em>kwargs)<br>∙ url : 拟更新页面的url链接<br>∙ data : 字典、字节序列或文件，Request的内容<br>∙ *</em>kwargs: 12个控制访问的参数</p><h2 id="requests-delete"><a href="#requests-delete" class="headerlink" title="requests.delete()"></a>requests.delete()</h2><p>requests.delete(url, *<em>kwargs)<br>∙ url : 拟删除页面的url链接<br>∙ *</em>kwargs: 12个控制访问的参数</p><h1 id="Requests库异常处理"><a href="#Requests库异常处理" class="headerlink" title="Requests库异常处理"></a>Requests库异常处理</h1><p>网络链接有风险，异常处理很重要。</p><p>爬虫时，会经常出现爬取失败的情况，以下为用Requests库所产生的六种常见异常</p><table><thead><tr><th>异常</th><th>说明</th></tr></thead><tbody><tr><td>requests.ConnectionError</td><td>网络连接错误异常，如DNS查询失败、拒绝连接等</td></tr><tr><td>requests.HTTPError</td><td>HTTP错误异常</td></tr><tr><td>requests.URLRequired</td><td>URL缺失异常</td></tr><tr><td>requests.TooManyRedirects</td><td>超过最大重定向次数，产生重定向异常</td></tr><tr><td>requests.ConnectTimeout</td><td>连接远程服务器超时异常，整个过程</td></tr><tr><td>requests.Timeout</td><td>请求URL超时，产生超时异常，仅只与服务器连接超时</td></tr></tbody></table><p><strong>r.raise_for_status()</strong><br>如果不是200，产生异常requests.HTTPError<br>r.raise_for_status()在方法内部判断r.status_code是否等于200，不需要<br>增加额外的if语句，该语句便于利用try‐except进行异常处理<br>可以有效处理爬取出现的问题异常，也可以使用except带异常类型处理<br><a href="https://www.runoob.com/python/python-exceptions.html" target="_blank" rel="noopener">异常类型处理学习</a></p><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Get_Html_Text</span><span class="hljs-params">(url)</span>:</span>    <span class="hljs-keyword">try</span>:        r = requests.get(url,timeout=<span class="hljs-number">30</span>)        r.raise_for_status()<span class="hljs-comment">#如果状态不是200，则产生HTTPERROR异常</span>        r.encoding = r.apparent_encoding        <span class="hljs-keyword">return</span> r.text    <span class="hljs-keyword">except</span>:        <span class="hljs-keyword">return</span> <span class="hljs-string">"产生异常"</span><span class="hljs-keyword">if</span> __name__==<span class="hljs-string">"__main__"</span>:    url = <span class="hljs-string">"http://www.baidu.com"</span>    print(Get_Html_Text(url))</code></pre>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>学习记录</tag>
      
      <tag>爬虫</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python进阶学习——爬虫初识，顺便立个Flag</title>
    <link href="/2020/08/05/python%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0%20%E2%80%94%20%E7%88%AC%E8%99%AB%E5%88%9D%E8%AF%86%EF%BC%8C%E9%A1%BA%E4%BE%BF%E7%AB%8B%E4%B8%AAFlag/"/>
    <url>/2020/08/05/python%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0%20%E2%80%94%20%E7%88%AC%E8%99%AB%E5%88%9D%E8%AF%86%EF%BC%8C%E9%A1%BA%E4%BE%BF%E7%AB%8B%E4%B8%AAFlag/</url>
    
    <content type="html"><![CDATA[<p>&emsp;断续续接触python一年多了，最近几个月，由于比赛原因一直在应用python，虽然接触了许多，但是实际代码水平，感觉提升的并不多。前段时间，看到一种说法，叫输出倒逼输入，虽然也在有道云笔记上也记了不少东西，但是自己做的，未免有些敷衍，故也乘此机会开始正式的写博客，逼自己学习一把。当然，水平有限，主要为了记录自己的学习，过路的大佬看看就好。<br>&emsp;关于python的进一步学习，我打算从爬虫开始，我个人方面，比较喜欢跟着一个固定的课程走，故而爬虫学习的主要部分是基于北京理工大学嵩天老师的python系列MOOC，各位也可直接点击以下链接去学习。<br><a href="https://www.icourse163.org/learn/BIT-1001870001?tid=1450316449#/learn/announce" target="_blank" rel="noopener">中国大学MOOC——北京理工大学—python网络爬虫与信息读取</a>     </p><p><strong><em>这篇主要为了立个Flag，从今天开始，至少每两天一更，尽量记录完这个Mooc的所有内容。希望不要被自己打脸。</em></strong>   </p><p>&emsp;首先呢，在开始学习之前，为了便于梳理，我决定还是明确几个常见难题，是什么，为什么，怎么做。</p><h1 id="爬虫是什么"><a href="#爬虫是什么" class="headerlink" title="爬虫是什么"></a>爬虫是什么</h1><p>&emsp;网络爬虫（又称为网页蜘蛛，网络机器人，在FOAF社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。——摘自百度百科<br>&emsp;简单来说就是通过编程去网上自动搜索或下载东西，比如说网上的图片，视频或者其它东西，基本上都可以通过编写代码去获取这些内容，并可以按照一定规则进行筛选。   </p><h1 id="为什么要学爬虫"><a href="#为什么要学爬虫" class="headerlink" title="为什么要学爬虫"></a>为什么要学爬虫</h1><p>&emsp;为什么要学爬虫，个人而言，为了好玩。学了爬虫能做很多事，比如爬取一些网站上的视频，快速爬取我想要的动漫图片、小说，亦或者没事闲的分析分析某些视频下的评论，B站上的弹幕等等。爬虫能够做到有效的从网络中自动筛选出你所需要的资源，同时也能快速获取大量精确信息。</p><h1 id="怎么学爬虫"><a href="#怎么学爬虫" class="headerlink" title="怎么学爬虫"></a>怎么学爬虫</h1><p>&emsp;同样，个人而言，在初学时，更喜欢系统性的学习，故而选择了跟着一个MOOC走，先把MOOC的内容搞定，之后自己没事写程序自己练习一下，同时还有一个原因是这样能有一个基础功底，只要你完成了课程的全部内容，哪怕后面你很久没有用到这门课程，再次学习也总会快很多，并且相关资料也容易找到。</p><p>&emsp;在MOOC里，嵩天老师指出这门课锻炼的是定向网络数据爬取和网页解析的基本能力，同时课程还传达了一个很重要的观念——The Website is API。<br>&emsp;信息可以通过接口（即API）获得，网页是一个接口，是获取信息的一个接口,而爬虫便是调用此接口的工具，我们可以自己定制这个工具，使其获取自己想要的特定信息。就像通过手机APP去获取公司的服务器数据一般。网页是信息的载体和接口。  </p><h1 id="基础工具"><a href="#基础工具" class="headerlink" title="基础工具"></a>基础工具</h1><p>&emsp;Requests库：可以自动爬取HTML页面，自动提交网络请求等，是爬虫的基础库之一<br>&emsp;robots协议（robots.txt）：网络爬取标准，是一种存放于网站根目录下的ASCII编码的文本文件，可以告诉你网页那些内容可以爬取，哪些不可以，是在使用爬虫时需要遵守的规则。<br>&emsp;Beautiful库：解析HTML页面，可以对已经爬取下来的网页内容进行解析和各种操作的库。<br>&emsp;Re：正则表达式，又称规则表达式，python中的正则表达式库。可以对信息进行精确提取和解析。<br>&emsp;Scrapy<em>：一个专业的网络爬虫框架，可以实现基础的更高级的爬虫。<br>（scrapy是适用于Python的一个快速、高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试。——百度百科）<br>*</em>开发环境为：windows，PyCharm 2019.3 x64，python3.7.**</p>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>学习记录</tag>
      
      <tag>爬虫</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>百度飞桨AI+python基础打卡营总结心得</title>
    <link href="/2020/05/01/%E7%99%BE%E5%BA%A6%E9%A3%9E%E6%A1%A8AI+python%E5%9F%BA%E7%A1%80%E6%89%93%E5%8D%A1%E8%90%A5%E6%80%BB%E7%BB%93%E5%BF%83%E5%BE%97/"/>
    <url>/2020/05/01/%E7%99%BE%E5%BA%A6%E9%A3%9E%E6%A1%A8AI+python%E5%9F%BA%E7%A1%80%E6%89%93%E5%8D%A1%E8%90%A5%E6%80%BB%E7%BB%93%E5%BF%83%E5%BE%97/</url>
    
    <content type="html"><![CDATA[<p>此次百度飞桨的python+AI的小白基础营，对我个人最大的收获便是在python的学习路上更进了一步步。参加训练营之前，学过C语言，python也大概学了好几个月，但中间中断过很多次，直到这次疫情，又重拾起了python的学习，之前参加过百度飞桨的疫情CV特辑，但只是非常勉强的完成了作业。此次的小白营，将我的学习从python的基础扩展到了爬虫和数据分析，也算是为后续的学习开了一个头。这篇总结心得主要是我对此次大作业的个人分析和总结（其它作业在另一篇博客里），如有错误，还望指正。</p><h2 id="综合大作业"><a href="#综合大作业" class="headerlink" title="综合大作业"></a>综合大作业</h2><p>第一步：爱奇艺《青春有你2》评论数据爬取(参考链接：<a href="https://www.iqiyi.com/v_19ryfkiv8w.html#curid=15068699100_9f9bab7e0d1e30c494622af777f4ba39" target="_blank" rel="noopener">https://www.iqiyi.com/v_19ryfkiv8w.html#curid=15068699100_9f9bab7e0d1e30c494622af777f4ba39</a>)<br>爬取任意一期正片视频下评论<br>评论条数不少于1000条<br>第二步：词频统计并可视化展示<br>数据预处理：清理清洗评论中特殊字符（如：@#￥%、emoji表情符）,清洗后结果存储为txt文档<br>中文分词：添加新增词（如：青你、奥利给、冲鸭），去除停用词（如：哦、因此、不然、也好、但是）<br>统计top10高频词<br>可视化展示高频词<br>第三步：绘制词云<br>根据词频生成词云<br>可选项-添加背景图片，根据背景图片轮廓生成词云<br>第四步：结合PaddleHub，对评论进行内容审核</p><p>需要的配置和准备<br>中文分词需要jieba<br>词云绘制需要wordcloud<br>可视化展示中需要的中文字体<br>网上公开资源中找一个中文停用词表<br>根据分词结果自己制作新增词表<br>准备一张词云背景图（附加项，不做要求，可用hub抠图实现）<br>paddlehub配置</p><h2 id="爬取评论（采用Chorm浏览器）"><a href="#爬取评论（采用Chorm浏览器）" class="headerlink" title="爬取评论（采用Chorm浏览器）"></a>爬取评论（采用Chorm浏览器）</h2><p>1：打开爱奇艺《青春有你2》的网页，随意选择一期（这里我选的是14期下），翻到评论部分底部， 我们会发现，评论区所对应的源码，在”查看更多评论部分“只有单独的语句，没有展开，同时点击查看更多评论时，评论会直接出现在评论列表中，如果直接爬取，无法满足评论数量要求，只能爬取一面评论。<br><img src="https://img-blog.csdnimg.cn/20200501184204328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>2：采用NetWork工具分析，可以查看到网页的各部分请求。刷新网页，再次发到评论底部，点击查看更多评论时，会产生一个get_comments请求<br><img src="https://img-blog.csdnimg.cn/20200501184204301.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>查看get_comments请求具体内容，从其preview中可以看到其具体信息，以看到评论内容，ID等信息，据此我们可以认为可以通过此命令来不断爬取评论。<br><img src="https://img-blog.csdnimg.cn/20200501184204181.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>3.查看其Request URL，可以获取评论的JSON信息，我们所爬取和下载的便是通过get_comments请求的URL获取的<br><img src="https://img-blog.csdnimg.cn/20200501184602203.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>4.重新刷新网页，在加载评论的过程中，我们会发现数个get_comments请求，逐一查看其内容，会发现，其last_id属性一直在变化，其它的几乎不变。<br><img src="https://img-blog.csdnimg.cn/20200501184624967.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200501184624974.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><p>5.通过以上分析，我们便可以通过不断改变last_id来获取更多评论，将上一次爬虫得到的last_id作为下一次爬虫的目标</p><pre><code class="hljs python"><span class="hljs-comment">#请求爱奇艺评论接口，返回response信息</span><span class="hljs-string">'''</span><span class="hljs-string">请求爱奇艺评论接口，返回response信息</span><span class="hljs-string">参数  url: 评论的url</span><span class="hljs-string">:return: response信息</span><span class="hljs-string">'''</span><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getMovieinfo</span><span class="hljs-params">(url)</span>:</span>    headers = &#123;        <span class="hljs-string">'User-Agent'</span>: <span class="hljs-string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'</span>    &#125;  <span class="hljs-comment"># 模仿数据请求，防止反爬虫</span>    <span class="hljs-comment">#爱奇艺第14期下</span>    response = requests.get(url,headers=headers)    <span class="hljs-keyword">return</span> response.text   解析json数据，获取评论参数  lastId:最后一条评论ID  arr:存放文本的list:<span class="hljs-keyword">return</span>: 新的lastId <span class="hljs-string">'''</span><span class="hljs-string">#解析json数据，获取评论</span><span class="hljs-string">def saveMovieInfoToFile(lastId,arr):</span><span class="hljs-string">    url ="https://sns-comment.iqiyi.com/v3/comment/get_comments.action?agent_type=118&amp;agent_version=9.11.5&amp;\authcookie=null&amp;business_type=17&amp;content_id=15535228800&amp;hot_size=0&amp;last_id="</span><span class="hljs-string"></span><span class="hljs-string">    url += str(lastId)</span><span class="hljs-string">    responseTxt = getMovieinfo(url) #获取网页</span><span class="hljs-string">    responseJson = json.loads(responseTxt)  #获取网页数据</span><span class="hljs-string">    comments = responseJson['data']['comments']  #获取评论数据（包括id，内容等）</span><span class="hljs-string">    for val in comments:</span><span class="hljs-string">        if 'content' in  val.keys():  #防止有val没有'conten'键</span><span class="hljs-string">            con = (val['content'])  #具体评论文本</span><span class="hljs-string">            #print(con)  #打印评论</span><span class="hljs-string">            arr.append(con)  #添加进arr</span><span class="hljs-string">    else:</span><span class="hljs-string">        lastId = str(val["id"])#最后一个id</span><span class="hljs-string">    return lastId</span></code></pre><h2 id="处理评论"><a href="#处理评论" class="headerlink" title="处理评论"></a>处理评论</h2><p>1：    去除文本特殊字符，特殊字符包括中英文标点符号，不可见字符，表情包等，可以通正则表达式处理，表情包的去除，则可以通过专门的emoji库，将表情转化为英文字符后再消除</p><pre><code class="hljs python"><span class="hljs-comment">#去除文本中特殊字符</span><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">clear_special_char</span><span class="hljs-params">(content)</span>:</span>    <span class="hljs-string">'''</span><span class="hljs-string">    正则处理特殊字符</span><span class="hljs-string">    参数 content:原文本</span><span class="hljs-string">    return: 清除后的文本</span><span class="hljs-string">    '''</span>    s = <span class="hljs-string">''</span>    <span class="hljs-comment">#将表情符转换成英文字符</span>    s = emoji.demojize(content)    <span class="hljs-comment">#去除不可见字符</span>    s = re.sub(<span class="hljs-string">'[\001\002\003\004\005\006\007\x08\x09\x0a\x0b\x0c\x0d\x0e\x0f\x10\x11\x12\x13\x14\x15\x16\x17\x18\x19\x1a]+'</span>, <span class="hljs-string">''</span>, s)    <span class="hljs-comment"># 去除中文，返回中文列表</span>    s = re.findall(<span class="hljs-string">r'[\u4e00-\u9fa5]'</span>, content)    <span class="hljs-comment">#重新转换成字符串</span>    s = <span class="hljs-string">''</span>.join(s)    <span class="hljs-keyword">return</span> s</code></pre><p>2：利用jieba分词，可以添加自定义词库，格式为</p><pre><code class="hljs python">刘雨昕虞书欣冲鸭奥利给</code></pre><p>自定义词库可以用来添加一些流行词汇或者人民，增加分词准确性</p><pre><code class="hljs python"><span class="hljs-string">'''</span><span class="hljs-string">利用jieba进行分词</span><span class="hljs-string">参数 text:需要分词的句子或文本</span><span class="hljs-string">return：分词后的评论列表</span><span class="hljs-string">'''</span><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fenci</span><span class="hljs-params">(content)</span>:</span>    <span class="hljs-comment">#jieba.load_userdict("data/add_words.txt")  #添加自定义分词典</span>    su = []    <span class="hljs-keyword">for</span> com <span class="hljs-keyword">in</span> content:        seg =jieba.lcut(com,cut_all=<span class="hljs-literal">False</span>)        <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> seg:            su.append(s)    <span class="hljs-keyword">return</span> su</code></pre><p>3.去除停用词，即去除类似于：”于是“，”然后“，”因为“，”所以“之类的词<br>停用词库：<a href="https://github.com/goto456/stopwords" target="_blank" rel="noopener">https://github.com/goto456/stopwords</a><br>由于停用词库，直接分割会产生换行符，故需要加一个函数用来将停用词库，转化成我们能直接使用分停用词列表，并根据实践效果，添加一些自定义的停用词，如以下代码中的”欣虞书”就是根据运行结果加的。</p><pre><code class="hljs python"><span class="hljs-string">'''</span><span class="hljs-string">创建停用词表</span><span class="hljs-string">参数 file_path:停用词文本路径</span><span class="hljs-string">return：停用词列表stop</span><span class="hljs-string">'''</span><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">stopwordslist</span><span class="hljs-params">(file_path)</span>:</span>    spc_word = [<span class="hljs-string">"欣虞书"</span>,<span class="hljs-string">"真的"</span>,<span class="hljs-string">"言喻"</span>,<span class="hljs-string">'一个'</span>,<span class="hljs-string">'啊啊啊'</span>,<span class="hljs-string">'镜头'</span>,<span class="hljs-string">'哈哈哈'</span>]  <span class="hljs-comment">#特殊停用词  </span>    stop = []  <span class="hljs-comment">#停用词列表</span>    f1 = open(file_path, <span class="hljs-string">"r"</span>, encoding=<span class="hljs-string">"utf-8"</span>)    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f1.readlines():        line = line.split(<span class="hljs-string">'\n'</span>)  <span class="hljs-comment"># 去除换行符</span>        stop.append(line[<span class="hljs-number">0</span>])  <span class="hljs-comment"># 添加进停用词列表</span>    <span class="hljs-comment">#print(stop)</span>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> spc_word:        stop.append(i) <span class="hljs-comment">#添加特殊停止词</span>    f1.close()     <span class="hljs-keyword">return</span> stop</code></pre><p>在获得可用的停用词库后，直接在评论分词列表中去除，同时利用字典的特性统计词频</p><pre><code class="hljs python"><span class="hljs-string">'''</span><span class="hljs-string">去除停用词,统计词频</span><span class="hljs-string">参数 file_path:停用词文本路径 stopwords:停用词list counts: 词频统计结果</span><span class="hljs-string">return con  #返回的是不带停用词的单词列表   </span><span class="hljs-string">'''</span><span class="hljs-comment">#content：完全净化后的评论词列表</span><span class="hljs-comment">#word_counts：词频字典</span><span class="hljs-comment">#停用词库来源：百度</span><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">movestopwords</span><span class="hljs-params">(file_path,content,word_counts)</span>:</span>    con = []    stop = stopwordslist(file_path)    <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> content:        <span class="hljs-keyword">if</span> s <span class="hljs-keyword">in</span> stop:            <span class="hljs-keyword">continue</span>        con.append(s)    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> con:        <span class="hljs-keyword">if</span>(len(word)!=<span class="hljs-number">1</span>):  <span class="hljs-comment">#如果存在就+1，如果不存在就创建</span>            word_counts[word] = word_counts.get(word,<span class="hljs-number">0</span>)+<span class="hljs-number">1</span>    <span class="hljs-keyword">return</span> con  <span class="hljs-comment">#返回的是不带停用词的单词列表</span></code></pre><h2 id="绘制词频统计图"><a href="#绘制词频统计图" class="headerlink" title="绘制词频统计图"></a>绘制词频统计图</h2><p>利用matplotlib库绘制词频统计图<br>‘’<br>词频统计图<br>‘’’<br>def drawcounts(s,num):<br>    # # 显示matplotlib生成的图形<br>    # % matplotlib inline<br>    x_aixs = []<br>    y_aixs = []<br>    c_order = sorted(s.items(),key=lambda x:x[1],reverse=True)  #排序<br>    for c in c_order[:num]:<br>        x_aixs.append(c[0])  #横坐标<br>        y_aixs.append(c[1])  #纵坐标<br>    # 设置显示中文<br>    plt.rcParams[‘font.sans-serif’] = [‘SimHei’] # 指定默认字体<br>    #plt.rcParams[‘axes.unciode_minus’] = False #解决保存图像是负号’-‘显示为方块的问题<br>    plt.bar(x_aixs,y_aixs)<br>    plt.title(‘’’词频统计’’’,fontsize = 24)<br>    plt.savefig(‘bar_result.jpg’)</p><h2 id="绘制词频词云"><a href="#绘制词频词云" class="headerlink" title="绘制词频词云"></a>绘制词频词云</h2><p>利用Wordcloud库绘制词云<br>‘’’<br>根据词频绘制词云图<br>参数 word_f:统计出的词频结果<br>return：none<br>‘’’<br>def drawcloud(word_f):<br>    cloud_mask = np.array(Image.open(‘cloud.jpg’))  #加载背景形状，转换成数组形式<br>    ignore = set([])  #忽略词</p><pre><code>wc = WordCloud(    background_color = &apos;white&apos;,    mask = cloud_mask,  #背景形状    max_words=100,  #显示词数    font_path=&apos;simhei.ttf&apos;,    min_font_size=10,  #最小尺寸    max_font_size=100,    width=1200,    relative_scaling=0.3,    stopwords=ignore,  #忽略词    mode=&apos;RGBA&apos;)wc.fit_words(word_f)  #填充词云wc.to_file(&apos;pic.png&apos;)</code></pre><h2 id="敏感词检测"><a href="#敏感词检测" class="headerlink" title="敏感词检测"></a>敏感词检测</h2><p>采用PaddleHub的porn_detection_lstm模型<br>‘’’<br>使用hub对评论进行内容分析<br>return：分析结果<br>‘’’<br>def text_detection(text):<br>    porn_detection_lstm = hub.Module(name=”porn_detection_lstm”)<br>    input_dict = {“text”:text}<br>    results = porn_detection_lstm.detection(data=input_dict,use_gpu=False,batch_size=1)  #训练结果<br>    #print(results)<br>    print(“可能敏感句子:”)<br>    for index,item in enumerate(results):<br>        if item[‘porn_detection_key’] == ‘porn’:<br>            print(item[‘text’],’:’,item[‘porn_probs’])</p><h2 id="主函数"><a href="#主函数" class="headerlink" title="主函数"></a>主函数</h2><p>#评论是多分页的，得多次请求爱奇艺的评论接口才能获取多页评论,有些评论含有表情、特殊字符之类的<br>#num为爬取</p><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:num = <span class="hljs-number">50</span> <span class="hljs-comment">#爬取评论数</span>    con = []<span class="hljs-comment">#含有特殊字符的评论</span>    content = []<span class="hljs-comment">#不含有特殊字符的评论</span>    count_words=&#123;&#125;  <span class="hljs-comment">#词频统计结果</span>    lastId = <span class="hljs-number">41040619521</span>  <span class="hljs-comment">#初始ID</span>    file_path =<span class="hljs-string">"data/baidu_stopwords.txt"</span>  <span class="hljs-comment">#停用词库地址</span>    jieba.load_userdict(<span class="hljs-string">"data/add_words.txt"</span>)  <span class="hljs-comment">#添加自定义分词典</span>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>,num):  <span class="hljs-comment">#控制评论数</span>        lastId = saveMovieInfoToFile(lastId,con)  <span class="hljs-comment">#改变了con，即增加了评论内容</span>        time.sleep(<span class="hljs-number">0.25</span>)  <span class="hljs-comment">#缓冲</span>    print(<span class="hljs-string">"共获取&#123;:&#125;条评论"</span>.format(len(con)))    <span class="hljs-comment"># print("净化后的评论：")</span>    <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> con:        s = clear_special_char(s)        <span class="hljs-keyword">if</span>(len(s)==<span class="hljs-number">0</span>):  <span class="hljs-comment">#去除空字符串</span>            <span class="hljs-keyword">continue</span>        content.append(s)    content = fenci(content)  <span class="hljs-comment">#分词</span>    content = movestopwords(file_path,content,count_words)  <span class="hljs-comment">#去除停用词,同时统计词频</span>    <span class="hljs-comment">#print(count_words)</span>    drawcounts(count_words,<span class="hljs-number">10</span>)    drawcloud(count_words)    print(<span class="hljs-string">"词云已完成"</span>)<span class="hljs-comment">#敏感句子检测</span>text_detection(con)</code></pre><p>运行结果：<br>（截止4月28号的）<br><img src="https://img-blog.csdnimg.cn/20200501185144527.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p><p>完整作业代码和数据：<br>链接：<a href="https://pan.baidu.com/s/1jckWsPattr10vxKMEeKrhw" target="_blank" rel="noopener">https://pan.baidu.com/s/1jckWsPattr10vxKMEeKrhw</a><br>提取码：82hu</p><p>扩展：爱奇艺内评论格式类似，所以此代码理论上可以爬取很多爱奇艺视频下的评论<br>如《小猪佩奇》：<img src="https://img-blog.csdnimg.cn/20200501190148517.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>飞桨</tag>
      
      <tag>心得体会</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于百度深度学习7日入门-CV疫情特辑的心得体会</title>
    <link href="/2020/04/07/%E5%85%B3%E4%BA%8E%E7%99%BE%E5%BA%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A07%E6%97%A5%E5%85%A5%E9%97%A8-CV%E7%96%AB%E6%83%85%E7%89%B9%E8%BE%91%E7%9A%84%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/"/>
    <url>/2020/04/07/%E5%85%B3%E4%BA%8E%E7%99%BE%E5%BA%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A07%E6%97%A5%E5%85%A5%E9%97%A8-CV%E7%96%AB%E6%83%85%E7%89%B9%E8%BE%91%E7%9A%84%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/</url>
    
    <content type="html"><![CDATA[<p>&emsp;本次参加了百度飞浆的7天训练营，最初的原因是从智能车卓晴老师那里引进来的，知道了这次课程和AIstudio这个平台，同时也因为自己也一直都想接触AI方面的知识和培训，但是一直没有找到合适的机会切入这一方面（当然，也是因为自己的拖延）。正好本届智能车和AI结合的颇为紧密，我也就下了决心完成这次训练营。<br>&emsp;此次训练营，要说我个人的最大收获，便是确实的了解和接触了那些神经网络和深度学习，而不是只停留在科普的层面，实践了DNN，CNN，vgg之类的网络结构，虽然作业除了第一天，后面几天的作业完成的都非常勉强。。。也让我再次明白了理论基础的重要性，基础理论不明白，后面实践真的还是挺难的。</p><p>&emsp;这几天我接触了许多的概念和基础术语，但作为一名完全没有接触过神经网络的外行，却依然有很多听不懂的，在这篇博客也记录一些，以下是我目前查询过的一些基础概念或术语简要概括，如果有兴趣可以自行去查询。</p><p><strong>NN</strong>：神经网络<br><strong>DNN</strong>：狭义上指全连接神经网络，广义上可以说隐层达到一定个数的都是深度神经网络<br><strong>CNN</strong>：卷积神经网络<br><strong>RNN</strong>：循环神经网络<br><img src="https://img-blog.csdnimg.cn/2020040715470370.png#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br><strong>前馈神经网络</strong>：是一种最简单的神经网络，各神经元分层排列。每个神经元只与前一层的神经元相连。接收前一层的输出，并输出给下一层．各层间没有反馈</p><p><strong>过拟合</strong>：过拟合是指为了得到一致假设而使假设变得过度严格。避免过拟合是分类器设计中的一个核心任务。通常采用增大数据量和测试样本集的方法对分类器性能进行评价。</p><p><strong>全局最优</strong>：针对一定条件/环境下的一个问题/目标，若一项决策和所有解决该问题的决策相比是最优的，就可以被称为全局最优。<br><strong>局部最优</strong>：局部最优，是指对于一个问题的解在一定范围或区域内最优，或者说解决问题或达成目标的手段在一定范围或限制内最优。<br>可以看到，局部最优不一定是全局最优，全局最优一定是局部最优。</p><p><strong>学习率(Learning rate)</strong>：作为监督学习以及深度学习中重要的超参，其决定着目标函数能否收敛到局部最小值以及何时收敛到最小值。合适的学习率能够使目标函数在合适的时间内收敛到局部最小值。</p><p><strong>知识蒸馏</strong>：<br>先训练一个teacher网络，然后使用这个teacher网络的输出和数据的真实标签去训练student网络。知识蒸馏，可以用来将网络从大网络转化成一个小网络，并保留接近于大网络的性能；也可以将多个网络的学到的知识转移到一个网络中，使得单个网络的性能接近类似的结果。</p><blockquote><p>作者：Ivan Yan 链接：<a href="https://zhuanlan.zhihu.com/p/81467832" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/81467832</a> 来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p></blockquote><p><strong>FLOPs</strong><br> 是floating point of operations的缩写，是浮点运算次数，可以用来衡量算法/模型复杂度。<br><strong>Pooling</strong>：池化，降低维度，类似于等比例缩小图片尺度，减少。</p><p><strong>迁移学习(Transfer learning)</strong> ：<br>是将在某个领域或任务上学习到的知识或模式应用到不同但相关的领域或问题中。</p><p><strong>Int8量化</strong><br>就是将原本大模型的’float32’转化为’int8’，使其模型尺寸更小、推断更快、耗电更低。唯一的缺点，模型精度会下降。</p><p><strong>NAS</strong>：<br>神经网络架构搜索，一种神经网络算法,<br>NAS的原理是给定一个称为搜索空间的候选神经网络结构集合，用某种策略从中搜索出最优网络结构。神经网络结构的优劣即性能用某些指标如精度、速度来度量，称为性能评估。这一过程如下图所示。<br>就是优化参数<br><img src="https://img-blog.csdnimg.cn/20200407154739280.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>飞桨</tag>
      
      <tag>心得体会</tag>
      
      <tag>CV</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>my first blog</title>
    <link href="/2020/03/17/my-first-blog/"/>
    <url>/2020/03/17/my-first-blog/</url>
    
    <content type="html"><![CDATA[<p>##第一章</p><p>内容</p><hr><p>##第二章</p><p>内容</p><hr>]]></content>
    
    
    <categories>
      
      <category>测试</category>
      
    </categories>
    
    
    <tags>
      
      <tag>测试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2020/03/17/hello-world/"/>
    <url>/2020/03/17/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="hljs bash">$ hexo new <span class="hljs-string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="hljs bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="hljs bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="hljs bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    
    <categories>
      
      <category>测试</category>
      
    </categories>
    
    
    <tags>
      
      <tag>测试</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
