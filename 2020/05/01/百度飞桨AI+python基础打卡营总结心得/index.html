<!DOCTYPE html>
<html lang="en">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/avatar.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="cloudray">
  <meta name="keywords" content="">
  <title>百度飞桨AI+python基础打卡营总结心得 - cloudray</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Cloudray</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-filjiel"></i>
                主页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner intro-2" id="background" parallax=true
         style="background: url('/img/%E7%94%B5%E5%AD%90.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fade-in-up">
            <span class="h2" id="subtitle">
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2020-05-01 19:07">
      May 1, 2020 pm
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      2.4k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      38
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
            <div class="scroll-down-bar">
              <i class="iconfont icon-arrowdown"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
              <p class="note note-info">
                
                  本文最后更新于：August 8, 2020 pm
                
              </p>
            
            <article class="markdown-body">
              <p>此次百度飞桨的python+AI的小白基础营，对我个人最大的收获便是在python的学习路上更进了一步步。参加训练营之前，学过C语言，python也大概学了好几个月，但中间中断过很多次，直到这次疫情，又重拾起了python的学习，之前参加过百度飞桨的疫情CV特辑，但只是非常勉强的完成了作业。此次的小白营，将我的学习从python的基础扩展到了爬虫和数据分析，也算是为后续的学习开了一个头。这篇总结心得主要是我对此次大作业的个人分析和总结（其它作业在另一篇博客里），如有错误，还望指正。</p>
<h2 id="综合大作业"><a href="#综合大作业" class="headerlink" title="综合大作业"></a>综合大作业</h2><p>第一步：爱奇艺《青春有你2》评论数据爬取(参考链接：<a href="https://www.iqiyi.com/v_19ryfkiv8w.html#curid=15068699100_9f9bab7e0d1e30c494622af777f4ba39" target="_blank" rel="noopener">https://www.iqiyi.com/v_19ryfkiv8w.html#curid=15068699100_9f9bab7e0d1e30c494622af777f4ba39</a>)<br>爬取任意一期正片视频下评论<br>评论条数不少于1000条<br>第二步：词频统计并可视化展示<br>数据预处理：清理清洗评论中特殊字符（如：@#￥%、emoji表情符）,清洗后结果存储为txt文档<br>中文分词：添加新增词（如：青你、奥利给、冲鸭），去除停用词（如：哦、因此、不然、也好、但是）<br>统计top10高频词<br>可视化展示高频词<br>第三步：绘制词云<br>根据词频生成词云<br>可选项-添加背景图片，根据背景图片轮廓生成词云<br>第四步：结合PaddleHub，对评论进行内容审核</p>
<p>需要的配置和准备<br>中文分词需要jieba<br>词云绘制需要wordcloud<br>可视化展示中需要的中文字体<br>网上公开资源中找一个中文停用词表<br>根据分词结果自己制作新增词表<br>准备一张词云背景图（附加项，不做要求，可用hub抠图实现）<br>paddlehub配置</p>
<h2 id="爬取评论（采用Chorm浏览器）"><a href="#爬取评论（采用Chorm浏览器）" class="headerlink" title="爬取评论（采用Chorm浏览器）"></a>爬取评论（采用Chorm浏览器）</h2><p>1：打开爱奇艺《青春有你2》的网页，随意选择一期（这里我选的是14期下），翻到评论部分底部， 我们会发现，评论区所对应的源码，在”查看更多评论部分“只有单独的语句，没有展开，同时点击查看更多评论时，评论会直接出现在评论列表中，如果直接爬取，无法满足评论数量要求，只能爬取一面评论。<br><img src="https://img-blog.csdnimg.cn/20200501184204328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>2：采用NetWork工具分析，可以查看到网页的各部分请求。刷新网页，再次发到评论底部，点击查看更多评论时，会产生一个get_comments请求<br><img src="https://img-blog.csdnimg.cn/20200501184204301.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>查看get_comments请求具体内容，从其preview中可以看到其具体信息，以看到评论内容，ID等信息，据此我们可以认为可以通过此命令来不断爬取评论。<br><img src="https://img-blog.csdnimg.cn/20200501184204181.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>3.查看其Request URL，可以获取评论的JSON信息，我们所爬取和下载的便是通过get_comments请求的URL获取的<br><img src="https://img-blog.csdnimg.cn/20200501184602203.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>4.重新刷新网页，在加载评论的过程中，我们会发现数个get_comments请求，逐一查看其内容，会发现，其last_id属性一直在变化，其它的几乎不变。<br><img src="https://img-blog.csdnimg.cn/20200501184624967.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200501184624974.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<p>5.通过以上分析，我们便可以通过不断改变last_id来获取更多评论，将上一次爬虫得到的last_id作为下一次爬虫的目标</p>
<pre><code class="hljs python"><span class="hljs-comment">#请求爱奇艺评论接口，返回response信息</span>
<span class="hljs-string">'''</span>
<span class="hljs-string">请求爱奇艺评论接口，返回response信息</span>
<span class="hljs-string">参数  url: 评论的url</span>
<span class="hljs-string">:return: response信息</span>
<span class="hljs-string">'''</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getMovieinfo</span><span class="hljs-params">(url)</span>:</span>
    headers = &#123;
        <span class="hljs-string">'User-Agent'</span>: <span class="hljs-string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'</span>
    &#125;  <span class="hljs-comment"># 模仿数据请求，防止反爬虫</span>

    <span class="hljs-comment">#爱奇艺第14期下</span>
    response = requests.get(url,headers=headers)
    <span class="hljs-keyword">return</span> response.text   
解析json数据，获取评论
参数  lastId:最后一条评论ID  arr:存放文本的list
:<span class="hljs-keyword">return</span>: 新的lastId
 <span class="hljs-string">'''</span>
<span class="hljs-string">#解析json数据，获取评论</span>
<span class="hljs-string">def saveMovieInfoToFile(lastId,arr):</span>
<span class="hljs-string">    url ="https://sns-comment.iqiyi.com/v3/comment/get_comments.action?agent_type=118&amp;agent_version=9.11.5&amp;\authcookie=null&amp;business_type=17&amp;content_id=15535228800&amp;hot_size=0&amp;last_id="</span>
<span class="hljs-string"></span>
<span class="hljs-string">    url += str(lastId)</span>
<span class="hljs-string">    responseTxt = getMovieinfo(url) #获取网页</span>
<span class="hljs-string">    responseJson = json.loads(responseTxt)  #获取网页数据</span>
<span class="hljs-string">    comments = responseJson['data']['comments']  #获取评论数据（包括id，内容等）</span>
<span class="hljs-string">    for val in comments:</span>
<span class="hljs-string">        if 'content' in  val.keys():  #防止有val没有'conten'键</span>
<span class="hljs-string">            con = (val['content'])  #具体评论文本</span>
<span class="hljs-string">            #print(con)  #打印评论</span>
<span class="hljs-string">            arr.append(con)  #添加进arr</span>
<span class="hljs-string">    else:</span>
<span class="hljs-string">        lastId = str(val["id"])#最后一个id</span>
<span class="hljs-string">    return lastId</span></code></pre>

<h2 id="处理评论"><a href="#处理评论" class="headerlink" title="处理评论"></a>处理评论</h2><p>1：    去除文本特殊字符，特殊字符包括中英文标点符号，不可见字符，表情包等，可以通正则表达式处理，表情包的去除，则可以通过专门的emoji库，将表情转化为英文字符后再消除</p>
<pre><code class="hljs python"><span class="hljs-comment">#去除文本中特殊字符</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">clear_special_char</span><span class="hljs-params">(content)</span>:</span>
    <span class="hljs-string">'''</span>
<span class="hljs-string">    正则处理特殊字符</span>
<span class="hljs-string">    参数 content:原文本</span>
<span class="hljs-string">    return: 清除后的文本</span>
<span class="hljs-string">    '''</span>
    s = <span class="hljs-string">''</span>
    <span class="hljs-comment">#将表情符转换成英文字符</span>
    s = emoji.demojize(content)
    <span class="hljs-comment">#去除不可见字符</span>
    s = re.sub(<span class="hljs-string">'[\001\002\003\004\005\006\007\x08\x09\x0a\x0b\x0c\x0d\x0e\x0f\x10\x11\x12\x13\x14\x15\x16\x17\x18\x19\x1a]+'</span>, <span class="hljs-string">''</span>, s)
    <span class="hljs-comment"># 去除中文，返回中文列表</span>
    s = re.findall(<span class="hljs-string">r'[\u4e00-\u9fa5]'</span>, content)
    <span class="hljs-comment">#重新转换成字符串</span>
    s = <span class="hljs-string">''</span>.join(s)
    <span class="hljs-keyword">return</span> s</code></pre>


<p>2：利用jieba分词，可以添加自定义词库，格式为</p>
<pre><code class="hljs python">刘雨昕
虞书欣
冲鸭
奥利给</code></pre>

<p>自定义词库可以用来添加一些流行词汇或者人民，增加分词准确性</p>
<pre><code class="hljs python"><span class="hljs-string">'''</span>
<span class="hljs-string">利用jieba进行分词</span>
<span class="hljs-string">参数 text:需要分词的句子或文本</span>
<span class="hljs-string">return：分词后的评论列表</span>
<span class="hljs-string">'''</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fenci</span><span class="hljs-params">(content)</span>:</span>
    <span class="hljs-comment">#jieba.load_userdict("data/add_words.txt")  #添加自定义分词典</span>
    su = []
    <span class="hljs-keyword">for</span> com <span class="hljs-keyword">in</span> content:
        seg =jieba.lcut(com,cut_all=<span class="hljs-literal">False</span>)
        <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> seg:
            su.append(s)
    <span class="hljs-keyword">return</span> su</code></pre>

<p>3.去除停用词，即去除类似于：”于是“，”然后“，”因为“，”所以“之类的词<br>停用词库：<a href="https://github.com/goto456/stopwords" target="_blank" rel="noopener">https://github.com/goto456/stopwords</a><br>由于停用词库，直接分割会产生换行符，故需要加一个函数用来将停用词库，转化成我们能直接使用分停用词列表，并根据实践效果，添加一些自定义的停用词，如以下代码中的”欣虞书”就是根据运行结果加的。</p>
<pre><code class="hljs python"><span class="hljs-string">'''</span>
<span class="hljs-string">创建停用词表</span>
<span class="hljs-string">参数 file_path:停用词文本路径</span>
<span class="hljs-string">return：停用词列表stop</span>
<span class="hljs-string">'''</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">stopwordslist</span><span class="hljs-params">(file_path)</span>:</span>
    spc_word = [<span class="hljs-string">"欣虞书"</span>,<span class="hljs-string">"真的"</span>,<span class="hljs-string">"言喻"</span>,<span class="hljs-string">'一个'</span>,<span class="hljs-string">'啊啊啊'</span>,<span class="hljs-string">'镜头'</span>,<span class="hljs-string">'哈哈哈'</span>]  <span class="hljs-comment">#特殊停用词  </span>
    stop = []  <span class="hljs-comment">#停用词列表</span>
    f1 = open(file_path, <span class="hljs-string">"r"</span>, encoding=<span class="hljs-string">"utf-8"</span>)
    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f1.readlines():
        line = line.split(<span class="hljs-string">'\n'</span>)  <span class="hljs-comment"># 去除换行符</span>
        stop.append(line[<span class="hljs-number">0</span>])  <span class="hljs-comment"># 添加进停用词列表</span>
    <span class="hljs-comment">#print(stop)</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> spc_word:
        stop.append(i) <span class="hljs-comment">#添加特殊停止词</span>
    f1.close() 
    <span class="hljs-keyword">return</span> stop</code></pre>

<p>在获得可用的停用词库后，直接在评论分词列表中去除，同时利用字典的特性统计词频</p>
<pre><code class="hljs python"><span class="hljs-string">'''</span>
<span class="hljs-string">去除停用词,统计词频</span>
<span class="hljs-string">参数 file_path:停用词文本路径 stopwords:停用词list counts: 词频统计结果</span>
<span class="hljs-string">return con  #返回的是不带停用词的单词列表   </span>
<span class="hljs-string">'''</span>
<span class="hljs-comment">#content：完全净化后的评论词列表</span>
<span class="hljs-comment">#word_counts：词频字典</span>
<span class="hljs-comment">#停用词库来源：百度</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">movestopwords</span><span class="hljs-params">(file_path,content,word_counts)</span>:</span>
    con = []
    stop = stopwordslist(file_path)
    <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> content:
        <span class="hljs-keyword">if</span> s <span class="hljs-keyword">in</span> stop:
            <span class="hljs-keyword">continue</span>
        con.append(s)
    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> con:
        <span class="hljs-keyword">if</span>(len(word)!=<span class="hljs-number">1</span>):  <span class="hljs-comment">#如果存在就+1，如果不存在就创建</span>
            word_counts[word] = word_counts.get(word,<span class="hljs-number">0</span>)+<span class="hljs-number">1</span>
    <span class="hljs-keyword">return</span> con  <span class="hljs-comment">#返回的是不带停用词的单词列表</span></code></pre>

<h2 id="绘制词频统计图"><a href="#绘制词频统计图" class="headerlink" title="绘制词频统计图"></a>绘制词频统计图</h2><p>利用matplotlib库绘制词频统计图<br>‘’<br>词频统计图<br>‘’’<br>def drawcounts(s,num):<br>    # # 显示matplotlib生成的图形<br>    # % matplotlib inline<br>    x_aixs = []<br>    y_aixs = []<br>    c_order = sorted(s.items(),key=lambda x:x[1],reverse=True)  #排序<br>    for c in c_order[:num]:<br>        x_aixs.append(c[0])  #横坐标<br>        y_aixs.append(c[1])  #纵坐标<br>    # 设置显示中文<br>    plt.rcParams[‘font.sans-serif’] = [‘SimHei’] # 指定默认字体<br>    #plt.rcParams[‘axes.unciode_minus’] = False #解决保存图像是负号’-‘显示为方块的问题<br>    plt.bar(x_aixs,y_aixs)<br>    plt.title(‘’’词频统计’’’,fontsize = 24)<br>    plt.savefig(‘bar_result.jpg’)</p>
<h2 id="绘制词频词云"><a href="#绘制词频词云" class="headerlink" title="绘制词频词云"></a>绘制词频词云</h2><p>利用Wordcloud库绘制词云<br>‘’’<br>根据词频绘制词云图<br>参数 word_f:统计出的词频结果<br>return：none<br>‘’’<br>def drawcloud(word_f):<br>    cloud_mask = np.array(Image.open(‘cloud.jpg’))  #加载背景形状，转换成数组形式<br>    ignore = set([])  #忽略词</p>
<pre><code>wc = WordCloud(
    background_color = &apos;white&apos;,
    mask = cloud_mask,  #背景形状
    max_words=100,  #显示词数
    font_path=&apos;simhei.ttf&apos;,
    min_font_size=10,  #最小尺寸
    max_font_size=100,
    width=1200,
    relative_scaling=0.3,
    stopwords=ignore,  #忽略词
    mode=&apos;RGBA&apos;)
wc.fit_words(word_f)  #填充词云
wc.to_file(&apos;pic.png&apos;)</code></pre><h2 id="敏感词检测"><a href="#敏感词检测" class="headerlink" title="敏感词检测"></a>敏感词检测</h2><p>采用PaddleHub的porn_detection_lstm模型<br>‘’’<br>使用hub对评论进行内容分析<br>return：分析结果<br>‘’’<br>def text_detection(text):<br>    porn_detection_lstm = hub.Module(name=”porn_detection_lstm”)<br>    input_dict = {“text”:text}<br>    results = porn_detection_lstm.detection(data=input_dict,use_gpu=False,batch_size=1)  #训练结果<br>    #print(results)<br>    print(“可能敏感句子:”)<br>    for index,item in enumerate(results):<br>        if item[‘porn_detection_key’] == ‘porn’:<br>            print(item[‘text’],’:’,item[‘porn_probs’])</p>
<h2 id="主函数"><a href="#主函数" class="headerlink" title="主函数"></a>主函数</h2><p>#评论是多分页的，得多次请求爱奇艺的评论接口才能获取多页评论,有些评论含有表情、特殊字符之类的<br>#num为爬取</p>
<pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:
	num = <span class="hljs-number">50</span> <span class="hljs-comment">#爬取评论数</span>
    con = []<span class="hljs-comment">#含有特殊字符的评论</span>
    content = []<span class="hljs-comment">#不含有特殊字符的评论</span>
    count_words=&#123;&#125;  <span class="hljs-comment">#词频统计结果</span>
    lastId = <span class="hljs-number">41040619521</span>  <span class="hljs-comment">#初始ID</span>
    file_path =<span class="hljs-string">"data/baidu_stopwords.txt"</span>  <span class="hljs-comment">#停用词库地址</span>
    jieba.load_userdict(<span class="hljs-string">"data/add_words.txt"</span>)  <span class="hljs-comment">#添加自定义分词典</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>,num):  <span class="hljs-comment">#控制评论数</span>
        lastId = saveMovieInfoToFile(lastId,con)  <span class="hljs-comment">#改变了con，即增加了评论内容</span>
        time.sleep(<span class="hljs-number">0.25</span>)  <span class="hljs-comment">#缓冲</span>
    print(<span class="hljs-string">"共获取&#123;:&#125;条评论"</span>.format(len(con)))
    <span class="hljs-comment"># print("净化后的评论：")</span>
    <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> con:
        s = clear_special_char(s)
        <span class="hljs-keyword">if</span>(len(s)==<span class="hljs-number">0</span>):  <span class="hljs-comment">#去除空字符串</span>
            <span class="hljs-keyword">continue</span>
        content.append(s)
    content = fenci(content)  <span class="hljs-comment">#分词</span>
    content = movestopwords(file_path,content,count_words)  <span class="hljs-comment">#去除停用词,同时统计词频</span>
    <span class="hljs-comment">#print(count_words)</span>
    drawcounts(count_words,<span class="hljs-number">10</span>)
    drawcloud(count_words)
    print(<span class="hljs-string">"词云已完成"</span>)

<span class="hljs-comment">#敏感句子检测</span>
text_detection(con)</code></pre>

<p>运行结果：<br>（截止4月28号的）<br><img src="https://img-blog.csdnimg.cn/20200501185144527.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<p>完整作业代码和数据：<br>链接：<a href="https://pan.baidu.com/s/1jckWsPattr10vxKMEeKrhw" target="_blank" rel="noopener">https://pan.baidu.com/s/1jckWsPattr10vxKMEeKrhw</a><br>提取码：82hu</p>
<p>扩展：爱奇艺内评论格式类似，所以此代码理论上可以爬取很多爱奇艺视频下的评论<br>如《小猪佩奇》：<img src="https://img-blog.csdnimg.cn/20200501190148517.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/python/">python</a>
                    
                      <a class="hover-with-bg" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E9%A3%9E%E6%A1%A8/">飞桨</a>
                    
                      <a class="hover-with-bg" href="/tags/%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/">心得体会</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" target="_blank" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2020/08/05/python%E8%BF%9B%E9%98%B6%E5%AD%A6%E4%B9%A0%20%E2%80%94%20%E7%88%AC%E8%99%AB%E5%88%9D%E8%AF%86%EF%BC%8C%E9%A1%BA%E4%BE%BF%E7%AB%8B%E4%B8%AAFlag/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">python进阶学习——爬虫初识，顺便立个Flag</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/04/07/%E5%85%B3%E4%BA%8E%E7%99%BE%E5%BA%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A07%E6%97%A5%E5%85%A5%E9%97%A8-CV%E7%96%AB%E6%83%85%E7%89%B9%E8%BE%91%E7%9A%84%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/">
                        <span class="hidden-mobile">关于百度深度学习7日入门-CV疫情特辑的心得体会</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


    

    
  </div>
</footer>
<div id="music163player">
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=1206866&auto=1&height=66"></iframe>
</div>
<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "百度飞桨AI+python基础打卡营总结心得&nbsp;",
      ],
      cursorChar: "",
      typeSpeed: 50,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>







  
  
    <script>
      !function (e, t, a) {
        function r() {
          for (var e = 0; e < s.length; e++) s[e].alpha <= 0 ? (t.body.removeChild(s[e].el), s.splice(e, 1)) : (s[e].y--, s[e].scale += .004, s[e].alpha -= .013, s[e].el.style.cssText = "left:" + s[e].x + "px;top:" + s[e].y + "px;opacity:" + s[e].alpha + ";transform:scale(" + s[e].scale + "," + s[e].scale + ") rotate(45deg);background:" + s[e].color + ";z-index:99999");
          requestAnimationFrame(r)
        }

        function n() {
          var t = "function" == typeof e.onclick && e.onclick;
          e.onclick = function (e) {
            t && t(), o(e)
          }
        }

        function o(e) {
          var a = t.createElement("div");
          a.className = "heart", s.push({
            el: a,
            x: e.clientX - 5,
            y: e.clientY - 5,
            scale: 1,
            alpha: 1,
            color: c()
          }), t.body.appendChild(a)
        }

        function i(e) {
          var a = t.createElement("style");
          a.type = "text/css";
          try {
            a.appendChild(t.createTextNode(e))
          } catch (t) {
            a.styleSheet.cssText = e
          }
          t.getElementsByTagName("head")[0].appendChild(a)
        }

        function c() {
          return "rgb(" + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + ")"
        }

        var s = [];
        e.requestAnimationFrame = e.requestAnimationFrame || e.webkitRequestAnimationFrame || e.mozRequestAnimationFrame || e.oRequestAnimationFrame || e.msRequestAnimationFrame || function (e) {
          setTimeout(e, 1e3 / 60)
        }, i(".heart{width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;}.heart:after{top: -5px;}.heart:before{left: -5px;}"), n(), r()
      }(window, document);
    </script>
  











  

  

  

  

  

  





<script src="/node_modules/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"node_modules/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/node_modules/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>
