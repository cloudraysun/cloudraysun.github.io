<!DOCTYPE html>
<html lang="en">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/avatar.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="cloudray">
  <meta name="keywords" content="">
  <title>百度飞桨AI+python基础打卡营总结心得_cloudray</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/5.12.1/css/all.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/mdbootstrap/4.13.0/css/mdb.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css" />

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link  rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css" />

<link  rel="stylesheet" href="/css/main.css" />


  <link defer rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />


<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>cloudray</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/links/">友链</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/%E7%94%B5%E5%AD%90.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <p class="mt-3 post-meta">
                  <i class="fas fa-calendar-alt" aria-hidden="true"></i>
                  Friday, May 1st 2020, 7:07 pm
                </p>
              

              <p class="mt-1">
                
                  
                  <span class="post-meta">
                    <i class="far fa-chart-bar"></i>
                    2.5k 字
                  </span>
                

                
                  
                  <span class="post-meta">
                      <i class="far fa-clock"></i>
                      10 分钟
                  </span>
                

                
              </p>
            
          </div>

          
            <div class="scroll-down-bar">
              <i class="fas fa-angle-down scroll-down-arrow"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5 z-depth-3" id="board">
          <div class="post-content mx-auto" id="post">
            
              <p
                class="note note-warning">本文最后更新于：Friday, May 1st 2020, 7:07 pm</p>
            
            <div class="markdown-body">
              <p>此次百度飞桨的python+AI的小白基础营，对我个人最大的收获便是在python的学习路上更进了一步步。参加训练营之前，学过C语言，python也大概学了好几个月，但中间中断过很多次，直到这次疫情，又重拾起了python的学习，之前参加过百度飞桨的疫情CV特辑，但只是非常勉强的完成了作业。此次的小白营，将我的学习从python的基础扩展到了爬虫和数据分析，也算是为后续的学习开了一个头。这篇总结心得主要是我对此次大作业的个人分析和总结（其它作业在另一篇博客里），如有错误，还望指正。</p>
<h2 id="综合大作业"><a href="#综合大作业" class="headerlink" title="综合大作业"></a>综合大作业</h2><p>第一步：爱奇艺《青春有你2》评论数据爬取(参考链接：<a href="https://www.iqiyi.com/v_19ryfkiv8w.html#curid=15068699100_9f9bab7e0d1e30c494622af777f4ba39" target="_blank" rel="noopener">https://www.iqiyi.com/v_19ryfkiv8w.html#curid=15068699100_9f9bab7e0d1e30c494622af777f4ba39</a>)<br>爬取任意一期正片视频下评论<br>评论条数不少于1000条<br>第二步：词频统计并可视化展示<br>数据预处理：清理清洗评论中特殊字符（如：@#￥%、emoji表情符）,清洗后结果存储为txt文档<br>中文分词：添加新增词（如：青你、奥利给、冲鸭），去除停用词（如：哦、因此、不然、也好、但是）<br>统计top10高频词<br>可视化展示高频词<br>第三步：绘制词云<br>根据词频生成词云<br>可选项-添加背景图片，根据背景图片轮廓生成词云<br>第四步：结合PaddleHub，对评论进行内容审核</p>
<p>需要的配置和准备<br>中文分词需要jieba<br>词云绘制需要wordcloud<br>可视化展示中需要的中文字体<br>网上公开资源中找一个中文停用词表<br>根据分词结果自己制作新增词表<br>准备一张词云背景图（附加项，不做要求，可用hub抠图实现）<br>paddlehub配置</p>
<h2 id="爬取评论（采用Chorm浏览器）"><a href="#爬取评论（采用Chorm浏览器）" class="headerlink" title="爬取评论（采用Chorm浏览器）"></a>爬取评论（采用Chorm浏览器）</h2><p>1：打开爱奇艺《青春有你2》的网页，随意选择一期（这里我选的是14期下），翻到评论部分底部， 我们会发现，评论区所对应的源码，在”查看更多评论部分“只有单独的语句，没有展开，同时点击查看更多评论时，评论会直接出现在评论列表中，如果直接爬取，无法满足评论数量要求，只能爬取一面评论。<br><img src="https://img-blog.csdnimg.cn/20200501184204328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>2：采用NetWork工具分析，可以查看到网页的各部分请求。刷新网页，再次发到评论底部，点击查看更多评论时，会产生一个get_comments请求<br><img src="https://img-blog.csdnimg.cn/20200501184204301.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>查看get_comments请求具体内容，从其preview中可以看到其具体信息，以看到评论内容，ID等信息，据此我们可以认为可以通过此命令来不断爬取评论。<br><img src="https://img-blog.csdnimg.cn/20200501184204181.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>3.查看其Request URL，可以获取评论的JSON信息，我们所爬取和下载的便是通过get_comments请求的URL获取的<br><img src="https://img-blog.csdnimg.cn/20200501184602203.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>4.重新刷新网页，在加载评论的过程中，我们会发现数个get_comments请求，逐一查看其内容，会发现，其last_id属性一直在变化，其它的几乎不变。<br><img src="https://img-blog.csdnimg.cn/20200501184624967.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200501184624974.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<p>5.通过以上分析，我们便可以通过不断改变last_id来获取更多评论，将上一次爬虫得到的last_id作为下一次爬虫的目标</p>
<pre><code class="python">#请求爱奇艺评论接口，返回response信息
&#39;&#39;&#39;
请求爱奇艺评论接口，返回response信息
参数  url: 评论的url
:return: response信息
&#39;&#39;&#39;
def getMovieinfo(url):
    headers = {
        &#39;User-Agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&#39;
    }  # 模仿数据请求，防止反爬虫

    #爱奇艺第14期下
    response = requests.get(url,headers=headers)
    return response.text   
解析json数据，获取评论
参数  lastId:最后一条评论ID  arr:存放文本的list
:return: 新的lastId
 &#39;&#39;&#39;
#解析json数据，获取评论
def saveMovieInfoToFile(lastId,arr):
    url =&quot;https://sns-comment.iqiyi.com/v3/comment/get_comments.action?agent_type=118&amp;agent_version=9.11.5&amp;\authcookie=null&amp;business_type=17&amp;content_id=15535228800&amp;hot_size=0&amp;last_id=&quot;

    url += str(lastId)
    responseTxt = getMovieinfo(url) #获取网页
    responseJson = json.loads(responseTxt)  #获取网页数据
    comments = responseJson[&#39;data&#39;][&#39;comments&#39;]  #获取评论数据（包括id，内容等）
    for val in comments:
        if &#39;content&#39; in  val.keys():  #防止有val没有&#39;conten&#39;键
            con = (val[&#39;content&#39;])  #具体评论文本
            #print(con)  #打印评论
            arr.append(con)  #添加进arr
    else:
        lastId = str(val[&quot;id&quot;])#最后一个id
    return lastId</code></pre>
<h2 id="处理评论"><a href="#处理评论" class="headerlink" title="处理评论"></a>处理评论</h2><p>1：    去除文本特殊字符，特殊字符包括中英文标点符号，不可见字符，表情包等，可以通正则表达式处理，表情包的去除，则可以通过专门的emoji库，将表情转化为英文字符后再消除</p>
<pre><code class="python">#去除文本中特殊字符
def clear_special_char(content):
    &#39;&#39;&#39;
    正则处理特殊字符
    参数 content:原文本
    return: 清除后的文本
    &#39;&#39;&#39;
    s = &#39;&#39;
    #将表情符转换成英文字符
    s = emoji.demojize(content)
    #去除不可见字符
    s = re.sub(&#39;[\001\002\003\004\005\006\007\x08\x09\x0a\x0b\x0c\x0d\x0e\x0f\x10\x11\x12\x13\x14\x15\x16\x17\x18\x19\x1a]+&#39;, &#39;&#39;, s)
    # 去除中文，返回中文列表
    s = re.findall(r&#39;[\u4e00-\u9fa5]&#39;, content)
    #重新转换成字符串
    s = &#39;&#39;.join(s)
    return s</code></pre>
<p>2：利用jieba分词，可以添加自定义词库，格式为</p>
<pre><code class="python">刘雨昕
虞书欣
冲鸭
奥利给</code></pre>
<p>自定义词库可以用来添加一些流行词汇或者人民，增加分词准确性</p>
<pre><code class="python">&#39;&#39;&#39;
利用jieba进行分词
参数 text:需要分词的句子或文本
return：分词后的评论列表
&#39;&#39;&#39;
def fenci(content):
    #jieba.load_userdict(&quot;data/add_words.txt&quot;)  #添加自定义分词典
    su = []
    for com in content:
        seg =jieba.lcut(com,cut_all=False)
        for s in seg:
            su.append(s)
    return su</code></pre>
<p>3.去除停用词，即去除类似于：”于是“，”然后“，”因为“，”所以“之类的词<br>停用词库：<a href="https://github.com/goto456/stopwords" target="_blank" rel="noopener">https://github.com/goto456/stopwords</a><br>由于停用词库，直接分割会产生换行符，故需要加一个函数用来将停用词库，转化成我们能直接使用分停用词列表，并根据实践效果，添加一些自定义的停用词，如以下代码中的”欣虞书”就是根据运行结果加的。</p>
<pre><code class="python">&#39;&#39;&#39;
创建停用词表
参数 file_path:停用词文本路径
return：停用词列表stop
&#39;&#39;&#39;
def stopwordslist(file_path):
    spc_word = [&quot;欣虞书&quot;,&quot;真的&quot;,&quot;言喻&quot;,&#39;一个&#39;,&#39;啊啊啊&#39;,&#39;镜头&#39;,&#39;哈哈哈&#39;]  #特殊停用词  
    stop = []  #停用词列表
    f1 = open(file_path, &quot;r&quot;, encoding=&quot;utf-8&quot;)
    for line in f1.readlines():
        line = line.split(&#39;\n&#39;)  # 去除换行符
        stop.append(line[0])  # 添加进停用词列表
    #print(stop)
    for i in spc_word:
        stop.append(i) #添加特殊停止词
    f1.close() 
    return stop</code></pre>
<p>在获得可用的停用词库后，直接在评论分词列表中去除，同时利用字典的特性统计词频</p>
<pre><code class="python">&#39;&#39;&#39;
去除停用词,统计词频
参数 file_path:停用词文本路径 stopwords:停用词list counts: 词频统计结果
return con  #返回的是不带停用词的单词列表   
&#39;&#39;&#39;
#content：完全净化后的评论词列表
#word_counts：词频字典
#停用词库来源：百度
def movestopwords(file_path,content,word_counts):
    con = []
    stop = stopwordslist(file_path)
    for s in content:
        if s in stop:
            continue
        con.append(s)
    for word in con:
        if(len(word)!=1):  #如果存在就+1，如果不存在就创建
            word_counts[word] = word_counts.get(word,0)+1
    return con  #返回的是不带停用词的单词列表    </code></pre>
<h2 id="绘制词频统计图"><a href="#绘制词频统计图" class="headerlink" title="绘制词频统计图"></a>绘制词频统计图</h2><p>利用matplotlib库绘制词频统计图<br>‘’<br>词频统计图<br>‘’’<br>def drawcounts(s,num):<br>    # # 显示matplotlib生成的图形<br>    # % matplotlib inline<br>    x_aixs = []<br>    y_aixs = []<br>    c_order = sorted(s.items(),key=lambda x:x[1],reverse=True)  #排序<br>    for c in c_order[:num]:<br>        x_aixs.append(c[0])  #横坐标<br>        y_aixs.append(c[1])  #纵坐标<br>    # 设置显示中文<br>    plt.rcParams[‘font.sans-serif’] = [‘SimHei’] # 指定默认字体<br>    #plt.rcParams[‘axes.unciode_minus’] = False #解决保存图像是负号’-‘显示为方块的问题<br>    plt.bar(x_aixs,y_aixs)<br>    plt.title(‘’’词频统计’’’,fontsize = 24)<br>    plt.savefig(‘bar_result.jpg’)</p>
<h2 id="绘制词频词云"><a href="#绘制词频词云" class="headerlink" title="绘制词频词云"></a>绘制词频词云</h2><p>利用Wordcloud库绘制词云<br>‘’’<br>根据词频绘制词云图<br>参数 word_f:统计出的词频结果<br>return：none<br>‘’’<br>def drawcloud(word_f):<br>    cloud_mask = np.array(Image.open(‘cloud.jpg’))  #加载背景形状，转换成数组形式<br>    ignore = set([])  #忽略词</p>
<pre><code>wc = WordCloud(
    background_color = &#39;white&#39;,
    mask = cloud_mask,  #背景形状
    max_words=100,  #显示词数
    font_path=&#39;simhei.ttf&#39;,
    min_font_size=10,  #最小尺寸
    max_font_size=100,
    width=1200,
    relative_scaling=0.3,
    stopwords=ignore,  #忽略词
    mode=&#39;RGBA&#39;)
wc.fit_words(word_f)  #填充词云
wc.to_file(&#39;pic.png&#39;)</code></pre><h2 id="敏感词检测"><a href="#敏感词检测" class="headerlink" title="敏感词检测"></a>敏感词检测</h2><p>采用PaddleHub的porn_detection_lstm模型<br>‘’’<br>使用hub对评论进行内容分析<br>return：分析结果<br>‘’’<br>def text_detection(text):<br>    porn_detection_lstm = hub.Module(name=”porn_detection_lstm”)<br>    input_dict = {“text”:text}<br>    results = porn_detection_lstm.detection(data=input_dict,use_gpu=False,batch_size=1)  #训练结果<br>    #print(results)<br>    print(“可能敏感句子:”)<br>    for index,item in enumerate(results):<br>        if item[‘porn_detection_key’] == ‘porn’:<br>            print(item[‘text’],’:’,item[‘porn_probs’])</p>
<h2 id="主函数"><a href="#主函数" class="headerlink" title="主函数"></a>主函数</h2><p>#评论是多分页的，得多次请求爱奇艺的评论接口才能获取多页评论,有些评论含有表情、特殊字符之类的<br>#num为爬取</p>
<pre><code class="python">if __name__ == &quot;__main__&quot;:
    num = 50 #爬取评论数
    con = []#含有特殊字符的评论
    content = []#不含有特殊字符的评论
    count_words={}  #词频统计结果
    lastId = 41040619521  #初始ID
    file_path =&quot;data/baidu_stopwords.txt&quot;  #停用词库地址
    jieba.load_userdict(&quot;data/add_words.txt&quot;)  #添加自定义分词典
    for i in range(0,num):  #控制评论数
        lastId = saveMovieInfoToFile(lastId,con)  #改变了con，即增加了评论内容
        time.sleep(0.25)  #缓冲
    print(&quot;共获取{:}条评论&quot;.format(len(con)))
    # print(&quot;净化后的评论：&quot;)
    for s in con:
        s = clear_special_char(s)
        if(len(s)==0):  #去除空字符串
            continue
        content.append(s)
    content = fenci(content)  #分词
    content = movestopwords(file_path,content,count_words)  #去除停用词,同时统计词频
    #print(count_words)
    drawcounts(count_words,10)
    drawcloud(count_words)
    print(&quot;词云已完成&quot;)

#敏感句子检测
text_detection(con)</code></pre>
<p>运行结果：<br>（截止4月28号的）<br><img src="https://img-blog.csdnimg.cn/20200501185144527.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70#pic_center" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>
<p>完整作业代码和数据：<br>链接：<a href="https://pan.baidu.com/s/1jckWsPattr10vxKMEeKrhw" target="_blank" rel="noopener">https://pan.baidu.com/s/1jckWsPattr10vxKMEeKrhw</a><br>提取码：82hu</p>
<p>扩展：爱奇艺内评论格式类似，所以此代码理论上可以爬取很多爱奇艺视频下的评论<br>如《小猪佩奇》：<img src="https://img-blog.csdnimg.cn/20200501190148517.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcyNjkxNA==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"></p>

            </div>
            <hr>
            <div>
              <p>
                
                
              </p>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/04/07/%E5%85%B3%E4%BA%8E%E7%99%BE%E5%BA%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A07%E6%97%A5%E5%85%A5%E9%97%A8-CV%E7%96%AB%E6%83%85%E7%89%B9%E8%BE%91%E7%9A%84%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/">
                        <span class="hidden-mobile">关于百度深度学习7日入门-CV疫情特辑的心得体会</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="fa fa-chevron-right"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

              
                <!-- Comments -->
                <div class="comments" id="comments">
                  
                  

                </div>
              
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc-start"></div>
<div id="toc">
  <p class="h5"><i class="far fa-list-alt"></i>&nbsp;TOC</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->

  <div class="col-lg-7 mx-auto nopadding-md">
    <div class="container custom post-content mx-auto">
      <img src="https://octodex.github.com/images/jetpacktocat.png" srcset="/img/loading.gif" class="rounded mx-auto d-block mt-5" style="width:150px; height:150px;">
    </div>
  </div>


    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    </div>
    
  <div>
    
      <!-- 不蒜子统计PV -->
      
      <span id="busuanzi_container_site_pv" style="display: none">
      总访问量 <span id="busuanzi_value_site_pv"></span> 次
    </span>
    
    
      <!-- 不蒜子统计UV -->
      
      <span id="busuanzi_container_site_uv" style="display: none">
      总访客数 <span id="busuanzi_value_site_uv"></span> 人
    </span>
    
  </div>


    

    
  </div>
</footer>

<div id="music163player">
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=1206866&auto=0&height=66"></iframe>
</div>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/popper.js/1.16.1/umd/popper.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="https://cdn.staticfile.org/mdbootstrap/4.13.0/js/mdb.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.10.0/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var navHeight = $('#navbar').height();
      var toc = $('#toc');
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;
      var tocLimMax = 2 * boardTop + boardCtn.height();

      $(window).scroll(function () {
        var tocLimMin = $('#toc-start').offset().top - navHeight;
        var scroH = document.body.scrollTop + document.documentElement.scrollTop;

        if (tocLimMin <= scroH && scroH <= tocLimMax) {
          toc.css({
            'display': 'block',
            'position': 'fixed',
            'top': navHeight,
          });
        } else if (scroH <= tocLimMin) {
          toc.css({
            'position': '',
            'top': '',
          });
        } else if (scroH > tocLimMax) {
          toc.css('display', 'none');
        }
      });
      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc > p').css('visibility', 'visible');
      }
      var offset = boardCtn.css('margin-right')
      $('#toc-ctn').css({
        'right': offset
      })
    });
  </script>





  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>





  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




<!-- Plugins -->



  <script  src="https://cdn.staticfile.org/prettify/188.0.0/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "百度飞桨AI+python基础打卡营总结心得&nbsp;",
      ],
      cursorChar: "",
      typeSpeed: 50,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script defer src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>





  
  
    <script>
      !function (e, t, a) {
        function r() {
          for (var e = 0; e < s.length; e++) s[e].alpha <= 0 ? (t.body.removeChild(s[e].el), s.splice(e, 1)) : (s[e].y--, s[e].scale += .004, s[e].alpha -= .013, s[e].el.style.cssText = "left:" + s[e].x + "px;top:" + s[e].y + "px;opacity:" + s[e].alpha + ";transform:scale(" + s[e].scale + "," + s[e].scale + ") rotate(45deg);background:" + s[e].color + ";z-index:99999");
          requestAnimationFrame(r)
        }

        function n() {
          var t = "function" == typeof e.onclick && e.onclick;
          e.onclick = function (e) {
            t && t(), o(e)
          }
        }

        function o(e) {
          var a = t.createElement("div");
          a.className = "heart", s.push({
            el: a,
            x: e.clientX - 5,
            y: e.clientY - 5,
            scale: 1,
            alpha: 1,
            color: c()
          }), t.body.appendChild(a)
        }

        function i(e) {
          var a = t.createElement("style");
          a.type = "text/css";
          try {
            a.appendChild(t.createTextNode(e))
          } catch (t) {
            a.styleSheet.cssText = e
          }
          t.getElementsByTagName("head")[0].appendChild(a)
        }

        function c() {
          return "rgb(" + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + ")"
        }

        var s = [];
        e.requestAnimationFrame = e.requestAnimationFrame || e.webkitRequestAnimationFrame || e.mozRequestAnimationFrame || e.oRequestAnimationFrame || e.msRequestAnimationFrame || function (e) {
          setTimeout(e, 1e3 / 60)
        }, i(".heart{width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;}.heart:after{top: -5px;}.heart:before{left: -5px;}"), n(), r()
      }(window, document);
    </script>
  








</body>
</html>
